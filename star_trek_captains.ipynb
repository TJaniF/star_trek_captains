{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0039179",
   "metadata": {},
   "source": [
    "# Star Trek Captains - an NLP inquiry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7fb102",
   "metadata": {},
   "source": [
    "The goal of this project was to train different classification models on lines our favorite captains have said and then see how the models fare on yet unseen bits of wisdom.  \n",
    "\n",
    "The scripts of the following series were included:\n",
    "- Star Trek: The Original Series (TOS)\n",
    "- Star Trek: The Next Generation (TNG)\n",
    "- Star Trek: Deep Space Nine (DS9)\n",
    "- Star Trek: Voyager (VOY)\n",
    "- Star Trek: Enterprise (ENT)\n",
    "\n",
    "All lines of the following captains were included, disregarding whether they were said in the original series the captain belongs to or in a crossover episode:\n",
    "- TOS: James T. Kirk (KIRK)\n",
    "- TNG: Jean-Luc Picard (PICARD)\n",
    "- DS9: Benjamin Sisko (SISKO)\n",
    "- VOY: Kathryn Janeway (JANEWAY)\n",
    "- ENT: Jonathan Archer (ARCHER)\n",
    "\n",
    "Notes: Lines from mirror/alternate universe characters were counted with their prime-universe characters. Lines said over comm were counted. Personal and captain's logs were not counted. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bce323",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "- [Introduction](#intro)\n",
    "- [Importing Packages](#import)\n",
    "- [Setting Visualization Parameters](#viz_paras)\n",
    "_________\n",
    "\n",
    "- [Data Acquisition](#dataacq)\n",
    "    - [Custom Scraping Funtions](#csf)\n",
    "    - [Data Extraction Functions](#fdataextr)\n",
    "    - [Combining Scraping and Extraction Functions](#combo_scrape_extr)\n",
    "    - [Data Scraping](#actual_scraping)\n",
    "    - [Converting to Dataframe and Saving to CSV](#convert_save)\n",
    "    \n",
    "___________\n",
    "- [Data Cleaning](#dataclean)\n",
    "    - [Reading in Data](#read_in_data)\n",
    "    - [Looking at Raw Data](#look_at_raw_data)\n",
    "    - [Dropping missing pages](#drop_missing_pages)\n",
    "    - [Seperating Lines per Character](#sep_lines_char)\n",
    "    - [Clean up Lines](#clean_up_lines)\n",
    "____________\n",
    "- [EDA](#eda)\n",
    "    - [Preparation of dataframes](#prep_df)\n",
    "    - [Total Word Counts and Average Number of Words per Line](#totalwc_avg_num_words)\n",
    "    - [Count all words including common english words](#wordcount_no_stopwords)\n",
    "    - [Analysing Frequency of Very Common Words](#analysing_freq_v_common)\n",
    "    - [Count all words excluding common english words](#wordcount_with_stopwords)\n",
    "    - [Wordclouds](#wordclouds)\n",
    "\n",
    "___________    \n",
    "    \n",
    "**Basic Models**\n",
    "\n",
    "- [Preparing Data for Basic Modelling](#prep_base_data)\n",
    "    - [Baseline Accuracy](#baseline)\n",
    "    - [Train/Test Splits](#ttsplits)\n",
    "- [Create Pipelines](#create_pipelines)\n",
    "    - [Create Vectorizers](#create_vectorizers)\n",
    "    - [Create Models](#create_models)\n",
    "    - [Create Pipelines with Param-Grids](#create_pipelines_2)\n",
    "- [Fitting Basic Models](#basic_models)\n",
    "    - [Modelling Functions](#modelling_functions)\n",
    "    - [Fit Basic Models (Vectorized Lines) for Kirk vs Picard](#fit_basic_models_kvp)\n",
    "    - [Fit Basic Models (Vectorized Lines) for all captains](#fit_basic_models_capt)\n",
    "\n",
    "- [Evaluating Basic Models](#eval_basic_models)\n",
    "    - [Model evaluation functions](#eval_functions)\n",
    "    - [Kirk vs Picard](#kirkvpicard_eval)\n",
    "        - [Logistic Regression -  Kirk vs Picard](#kirkvpicard_logreg)\n",
    "        - [Decision Tree -  Kirk vs Picard](#kirkvpicard_dectree)\n",
    "        - [Bernoulli Native Bayes - Kirk vs Picard](#kirkvpicard_bayes)\n",
    "    - [All captains](#allc_eval)\n",
    "        - [Logistic Regression - all captains](#allc_logreg_eval)\n",
    "        - [Decision Tree - all captains](#allc_dectree_eval)\n",
    "        \n",
    "        \n",
    "_________\n",
    "        \n",
    "**Additional features**\n",
    "\n",
    "- [Importing GloVe Embeddings](#import_glove)\n",
    "- [GloVe feature engineering functions](#create_glove_functions)\n",
    "    - [Find the average word](#find_avg_word)\n",
    "- [Create Features from GloVe Embeddings](#create_glove_features)\n",
    "- [Combine Additional Features](#combine_adv_features)\n",
    "    - [Train-Test Split](#tts_advanced)\n",
    "    - [Feature Scaling](#scaling_adv)\n",
    "- [Create a Model only using the Additional Features](#create_model_adv_fea)\n",
    "- [Fitting a Logistic Regression on only Additional Features](#fit_model_only_adv_fea)\n",
    "- [Evaluating Logistic Regression with only Additional Features](#eval_models_only_adv_fea)\n",
    "\n",
    "_________\n",
    "\n",
    "**Combined Models**\n",
    "\n",
    "- [Combination of Wordvectors and Advanced Features](#combo_wordvec_adv_fea)\n",
    "    - [Kirk vs Picard](#combo_kvp)\n",
    "    - [All Captains](#combo_allc)\n",
    "    \n",
    "- [XGBoosted Random Forest](#xgb_main)\n",
    "    \n",
    "__________    \n",
    "- [Interaction Networks](#interaction_networks)\n",
    "\n",
    "- [Export Data for the Browser Game](#exp_data_game)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156ab658",
   "metadata": {},
   "source": [
    "<a name=\"import\"></a>\n",
    "#### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526459ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# Scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Feature Engineering\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy import spatial\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# Modelling General\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Boosting\n",
    "import xgboost as xgb\n",
    "\n",
    "# Viz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "import scikitplot as skplt\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import imageio as iio\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve, plot_precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "import scikitplot as skplt\n",
    "\n",
    "# Networks\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bdf9c7",
   "metadata": {},
   "source": [
    "<a name=\"viz_paras\"></a>\n",
    "#### Setting visualization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc19d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.family\"] = \"DIN Condensed\"\n",
    "plt.rcParams[\"font.size\"]  = 20       \n",
    "plt.rcParams[\"axes.edgecolor\"] = \"black\"\n",
    "plt.rcParams[\"axes.facecolor\"] =\"white\"\n",
    "plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4890e1c",
   "metadata": {},
   "source": [
    "<a name=\"dataacq\"></a>\n",
    "## Data Acquisition\n",
    "\n",
    "Data was scraped from <a href=\"http://www.chakoteya.net/StarTrek/index.html\">chakoteya.net</a> using a set of custom made functions and Packages `BeautifulSoup` and `requests`. \n",
    "\n",
    "**Section Overview**:\n",
    "- [Custom Scraping Functions](#csf)\n",
    "- [Data Extraction Functions](#fdataextr)\n",
    "- [Combining Scraping and Extraction Functions](#combo_scrape_extr)\n",
    "- [Data Scraping](#actual_scraping)\n",
    "- [Converting to Dataframe and Saving to CSV](#convert_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d3cfe1",
   "metadata": {},
   "source": [
    "<a name=\"csf\"></a>\n",
    "#### Custom Scraping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0367a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_chakoteyanet_one_script(base_url, page_number):\n",
    "    \"\"\" Scrapes one script page from chakoteyanet.com\n",
    "    Arguments:\n",
    "        base_url = baseline url to scrape with placeholder for page number like this: {}\n",
    "        page_number = number in url access a specific page \"\"\"\n",
    "\n",
    "    URL = base_url.format(page_number)\n",
    "    req = requests.get(URL)\n",
    "    soup = BeautifulSoup(req.text, \"html.parser\")    \n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84da312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_chakoteyanet_full_series(base_url, max_episode_number, starting_episode_number):\n",
    "    \"\"\" Scrapes all scripts of one series from chakoteyanet.com\n",
    "    Uses scraping_chakoteyanet_one_script()\n",
    "    Arguments:\n",
    "        base_url = baseline url to scrape with {}-placeholder for page number to iterate over\n",
    "        max_episode_number = page number of the last episode\n",
    "        starting_episode_number = page number of the first episode \"\"\"\n",
    "    \n",
    "    soups_all_episodes = []\n",
    "    \n",
    "    # iterating over all pages associated with a series\n",
    "    for i in range(starting_episode_number, max_episode_number+1):   \n",
    "        page_number = i\n",
    "        soup = scraping_chakoteyanet_one_script(base_url, page_number)\n",
    "        soups_all_episodes.append(soup)\n",
    "        \n",
    "    return soups_all_episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87478e3",
   "metadata": {},
   "source": [
    "<a name=\"fdataextr\"></a>\n",
    "#### Functions for Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2049c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_formatting_characters(text):\n",
    "    \"\"\" Replaces both \\r and \\n in a string with a whitespace\n",
    "    Arguments:\n",
    "        text = text to clean\"\"\"\n",
    "    text = text.replace(\"\\r\", \" \")\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f7a075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_episode_information(soup):\n",
    "    \"\"\"Extracts the information on top of the page (episode title, date etc).\n",
    "    Arguments:\n",
    "        soup = soup of the whole page scraped\"\"\"\n",
    "    return soup.find_all(\"p\")[0].text\n",
    "\n",
    "\n",
    "def extract_episode_script(soup):\n",
    "    \"\"\"Extracts the full text of the episode script.  \n",
    "    Arguments:\n",
    "        soup = soup of the whole page scraped\"\"\"\n",
    "    return soup.find_all(\"center\")[0].text\n",
    "\n",
    "\n",
    "def extract_title(episode_information_cleaned):\n",
    "    \"\"\"Extracts the title of the episode from the cleaned information section.\n",
    "    Arguments:\n",
    "        episode_information_cleaned = clean episode information (no formatting characters), \n",
    "        use replace_formatting_characters() for cleaning.\"\"\"\n",
    "    try:\n",
    "        if \"Stardate\" in episode_information_cleaned: # used in TOS, TNG, VOY, DS9\n",
    "            episode_title = re.findall(\".+?(?=Stardate)\", episode_information_cleaned)[0].strip(\"\")\n",
    "        if \"Mission date\" in episode_information_cleaned: # used in ENT\n",
    "            episode_title = re.findall(\".+?(?=Mission date)\", episode_information_cleaned)[0].strip(\"\")\n",
    "        else: # some episodes do not have a star date assigned\n",
    "            episode_title = episode_information_cleaned.strip(\"\")\n",
    "    except:\n",
    "        episode_title = np.nan    \n",
    "    \n",
    "    return episode_title\n",
    "\n",
    "\n",
    "def extract_stardate(episode_information_cleaned):\n",
    "    \"\"\"Extracts the stardate of the episode (if known) from the cleaned information section.\n",
    "    Arguments:\n",
    "        episode_information_cleaned = clean episode information (no formatting characters), \n",
    "        use replace_formatting_characters() for cleaning.\"\"\"\n",
    "    try:\n",
    "        episode_stardate = re.findall(\"Stardate:\\s+(\\S+)\", episode_information_cleaned)[0].strip(\"\")\n",
    "    except:\n",
    "        episode_stardate = np.nan     \n",
    "    \n",
    "    return episode_stardate\n",
    "\n",
    "\n",
    "def extract_mission_date(episode_information_cleaned):\n",
    "    \"\"\"Extracts the mission date of the episode (if known) from the cleaned information section.\n",
    "    (This only applies to ENT.)\n",
    "    Arguments:\n",
    "        episode_information_cleaned = clean episode information (no formatting characters), \n",
    "        use replace_formatting_characters() for cleaning.\"\"\"\n",
    "    try:\n",
    "        episode_missiondate = re.findall(\"Mission [dD]ate:\\s+(.+)Ori\", episode_information_cleaned)[0].strip(\"\")\n",
    "    except:\n",
    "        episode_missiondate = np.nan     \n",
    "    \n",
    "    return episode_missiondate\n",
    "\n",
    "\n",
    "def extract_airdate(episode_information_cleaned):\n",
    "    \"\"\"Extracts the original air date of the episode (if known) from the cleaned information section.\n",
    "    Arguments:\n",
    "        episode_information_cleaned = clean episode information (no formatting characters), \n",
    "        use replace_formatting_characters() for cleaning.\"\"\"\n",
    "    try:\n",
    "        episode_original_airdate = re.findall(\"Original Airdate:\\s(.+)\", \n",
    "                                              episode_information_cleaned)[0].strip(\"\")\n",
    "    except:\n",
    "        episode_original_airdate = np.nan   \n",
    "        \n",
    "    return episode_original_airdate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabebe08",
   "metadata": {},
   "source": [
    "<a name=\"combo_scrape_extr\"></a>\n",
    "#### Combining Scraping and Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63baa752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup_to_series_dictionary(series_name, base_url, series_dictionary, max_episode_number, \n",
    "                              starting_episode_number):\n",
    "    \n",
    "    \"\"\" Calls scraping function for a episodes of a series, iterates over raw soups and calls extraction functions\n",
    "    for title, stardate, original airdate and script.\n",
    "    Arguments:\n",
    "        series_name = name of the series scraped for print statement\n",
    "        base_url = baseline url to scrape with {}-placeholder for page number to iterate over\n",
    "        max_episode_number = page number of the last episode\n",
    "        starting_episode_number = page number of the first episode\n",
    "        series_dictionary = empty dictionary to fill with series information.\"\"\"\n",
    "    \n",
    "    # gather full page soups using the functions defined above\n",
    "    soups_all_episodes = scraping_chakoteyanet_full_series(base_url, max_episode_number, starting_episode_number)\n",
    "    \n",
    "    # iterate over the scraped soups to extract information\n",
    "    for i, soup in enumerate(soups_all_episodes):\n",
    "        \n",
    "        try:\n",
    "            episode_information = extract_episode_information(soup)  # information such as title and star date\n",
    "            episode_information_cleaned = replace_formatting_characters(episode_information)\n",
    "\n",
    "            episode_script = extract_episode_script(soup) # actual episode script\n",
    "            episode_script_cleaned = replace_formatting_characters(episode_script)\n",
    "            \n",
    "        except:\n",
    "            for key in series_dictionary.keys():\n",
    "                series_dictionary[key].append(np.nan)  \n",
    "        \n",
    "        episode_title = extract_title(episode_information_cleaned)\n",
    "        episode_stardate = extract_stardate(episode_information_cleaned)\n",
    "        episode_mission_date = extract_mission_date(episode_information_cleaned) # only used in ENT\n",
    "        episode_original_airdate = extract_airdate(episode_information_cleaned)\n",
    "        \n",
    "        episode_production_number = i+starting_episode_number # prod number is not always order of episodes aired\n",
    "\n",
    "        # collect the information in a dictionary\n",
    "        series_dictionary[\"title\"].append(episode_title)\n",
    "        series_dictionary[\"stardate\"].append(episode_stardate)\n",
    "        series_dictionary[\"mission_date\"].append(episode_mission_date)\n",
    "        series_dictionary[\"original_airdate\"].append(episode_original_airdate)\n",
    "        series_dictionary[\"production_number\"].append(episode_production_number)\n",
    "        series_dictionary[\"script\"].append(episode_script_cleaned)\n",
    "        \n",
    "    return f\"Successfully scraped {series_name} into {series_dictionary}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6f4a98",
   "metadata": {},
   "source": [
    "<a name=\"actual_scraping\"></a>\n",
    "#### Scraping \n",
    "\n",
    "Data was scraped from <a href=\"http://www.chakoteya.net/StarTrek/index.html\">chakoteya.net</a> for the series TOS, TNG, DS9, VOY, ENT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adfe528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template dictionary for datastructure\n",
    "dict_series = {\"title\": [],\n",
    "            \"stardate\" : [],\n",
    "            \"mission_date\" : [],\n",
    "            \"original_airdate\": [],\n",
    "            \"production_number\": [],\n",
    "            \"script\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8c802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the original series\n",
    "dict_TOS = copy.deepcopy(dict_series)\n",
    "url_TOS = \"http://www.chakoteya.net/StarTrek/{}.htm\"\n",
    "\n",
    "soup_to_series_dictionary(series_name = \"TOS\", base_url = url_TOS, series_dictionary = dict_TOS, \n",
    "                          max_episode_number = 79, starting_episode_number = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0919746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the next generation\n",
    "dict_TNG = copy.deepcopy(dict_series)\n",
    "url_TNG = \"http://www.chakoteya.net/NextGen/{}.htm\"\n",
    "\n",
    "soup_to_series_dictionary(series_name = \"TNG\", base_url = url_TNG, series_dictionary = dict_TNG, \n",
    "                          max_episode_number = 277, starting_episode_number = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd854c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Deep Space 9\n",
    "dict_DS9 = copy.deepcopy(dict_series)\n",
    "url_DS9 = \"http://www.chakoteya.net/DS9/{}.htm\"\n",
    "\n",
    "soup_to_series_dictionary(series_name = \"DS9\", base_url = url_DS9, series_dictionary = dict_DS9, \n",
    "                          max_episode_number = 575, starting_episode_number = 401)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98262244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Voyager episodes first season\n",
    "dict_VOY = copy.deepcopy(dict_series)\n",
    "url_VOY = \"http://www.chakoteya.net/Voyager/{}.htm\"\n",
    "\n",
    "soup_to_series_dictionary(series_name = \"VOY\", base_url = url_VOY, series_dictionary = dict_VOY, \n",
    "                          max_episode_number = 119, starting_episode_number = 101)\n",
    "\n",
    "\n",
    "# scraping Voyager second season (seperatly because of gaps in URL numbering)\n",
    "url_VOY = \"http://www.chakoteya.net/Voyager/{}.htm\"\n",
    "\n",
    "soup_to_series_dictionary(series_name = \"VOY\", base_url = url_VOY, series_dictionary = dict_VOY, \n",
    "                          max_episode_number = 225, starting_episode_number = 201)\n",
    "\n",
    "\n",
    "# scraping Voyager third season (seperatly because of gaps in URL numbering)\n",
    "url_VOY = \"http://www.chakoteya.net/Voyager/{}.htm\"\n",
    "\n",
    "soup_to_series_dictionary(series_name = \"VOY\", base_url = url_VOY, series_dictionary = dict_VOY, \n",
    "                          max_episode_number = 321, starting_episode_number = 301)\n",
    "\n",
    "\n",
    "# scraping Voyager fourth season (seperatly because of gaps in URL numbering)\n",
    "url_VOY = \"http://www.chakoteya.net/Voyager/{}.htm\"\n",
    "\n",
    "soup_to_series_dictionary(series_name = \"VOY\", base_url = url_VOY, series_dictionary = dict_VOY, \n",
    "                          max_episode_number = 423, starting_episode_number = 401)\n",
    "\n",
    "\n",
    "# scraping Voyager fifth season (seperatly because of gaps in URL numbering)\n",
    "url_VOY = \"http://www.chakoteya.net/Voyager/{}.htm\"\n",
    "\n",
    "soup_to_series_dictionary(series_name = \"VOY\", base_url = url_VOY, series_dictionary = dict_VOY, \n",
    "                          max_episode_number = 525, starting_episode_number = 501)\n",
    "\n",
    "\n",
    "# scraping Voyager sixth season (seperatly because of gaps in URL numbering)\n",
    "url_VOY = \"http://www.chakoteya.net/Voyager/{}.htm\"\n",
    "\n",
    "soup_to_series_dictionary(series_name = \"VOY\", base_url = url_VOY, series_dictionary = dict_VOY, \n",
    "                          max_episode_number = 625, starting_episode_number = 601)\n",
    "\n",
    "# scraping Voyager seventh season (seperatly because of gaps in URL numbering)\n",
    "url_VOY = \"http://www.chakoteya.net/Voyager/{}.htm\"\n",
    "\n",
    "soup_to_series_dictionary(series_name = \"VOY\", base_url = url_VOY, series_dictionary = dict_VOY, \n",
    "                          max_episode_number = 722, starting_episode_number = 701)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9453140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Enterprise 01 to 09 (seperatly because of additional 0 in URL)\n",
    "dict_ENT = dict_series.copy()\n",
    "url_ENT = \"http://www.chakoteya.net/Enterprise/0{}.htm\"\n",
    "\n",
    "soup_to_series_dictionary(series_name = \"ENT\", base_url = url_ENT, series_dictionary = dict_ENT, \n",
    "                          max_episode_number = 9, starting_episode_number = 1)\n",
    "\n",
    "\n",
    "# scraping Enterprise 10 to 98\n",
    "url_ENT = \"http://www.chakoteya.net/Enterprise/{}.htm\"\n",
    "\n",
    "soup_to_series_dictionary(series_name = \"ENT\", base_url = url_ENT, series_dictionary = dict_ENT, \n",
    "                          max_episode_number = 98, starting_episode_number = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aaa417",
   "metadata": {},
   "source": [
    "<a name=\"convert_save\"></a>\n",
    "#### Converting to Dataframe and Saving to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb97c204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting dictionaries to pandas dataframes\n",
    "df_TOS_scraped = pd.DataFrame(dict_TOS)\n",
    "df_TNG_scraped = pd.DataFrame(dict_TNG)\n",
    "df_DS9_scraped = pd.DataFrame(dict_DS9)\n",
    "df_VOY_scraped = pd.DataFrame(dict_VOY)\n",
    "df_ENT_scraped = pd.DataFrame(dict_ENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb1f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_destiny = \"../scraped_csvs/\"\n",
    "\n",
    "df_TOS_scraped.to_csv(saving_destiny + \"_scripts_TOS.csv\")\n",
    "df_TNG_scraped.to_csv(saving_destiny + \"_scripts_TNG.csv\")\n",
    "df_DS9_scraped.to_csv(saving_destiny + \"_scripts_DS9.csv\")\n",
    "df_VOY_scraped.to_csv(saving_destiny + \"_scripts_VOY.csv\")\n",
    "df_ENT_scraped.to_csv(saving_destiny + \"_scripts_ENT.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851f2f4e",
   "metadata": {},
   "source": [
    "<a name=\"dataclean\"></a>\n",
    "## Data Cleaning\n",
    "\n",
    "In this section the scripts of the episodes gathered was processed in order to collect all lines of the characters of interest and remove non-spoken text like for example stage directions.\n",
    "\n",
    "**Section overview**:\n",
    "- [Reading in Data](#read_in_data)  \n",
    "- [Looking at Raw Data](#look_at_raw_data)  \n",
    "- [Dropping Missing Pages](#drop_missing_pages)  \n",
    "- [Seperating Lines per Character](#sep_lines_char)  \n",
    "- [Clean up Lines](#clean_up_lines)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e4287c",
   "metadata": {},
   "source": [
    "<a name=\"read_in_data\"></a>\n",
    "#### Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a55a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in scraped data from csv\n",
    "df_TOS_raw = pd.read_csv(\"./scraped_csvs/_scripts_TOS.csv\", index_col=0)\n",
    "df_TNG_raw = pd.read_csv(\"./scraped_csvs/_scripts_TNG.csv\", index_col=0)\n",
    "df_DS9_raw = pd.read_csv(\"./scraped_csvs/_scripts_DS9.csv\", index_col=0)\n",
    "df_VOY_raw = pd.read_csv(\"./scraped_csvs/_scripts_VOY.csv\", index_col=0)\n",
    "df_ENT_raw = pd.read_csv(\"./scraped_csvs/_scripts_ENT.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46834bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping empty columns (ENT did not use stardate yet)\n",
    "df_ENT_raw.drop(columns=[\"stardate\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a983c6ea",
   "metadata": {},
   "source": [
    "<a name=\"look_at_raw_data\"></a>\n",
    "#### Looking at Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d344e7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TOS_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TNG_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dced7688",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DS9_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e417d5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VOY_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d54ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ENT_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a952084",
   "metadata": {},
   "source": [
    "<a name=\"drop_missing_pages\"></a>\n",
    "#### Dropping Mssing Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f348315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_bad_htm_pages(dataframe_raw):\n",
    "    for i,title in enumerate(dataframe_raw.title):\n",
    "        if \"WordPress\" in title:\n",
    "            dataframe_raw.drop(index=i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687adac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping htm pages that did not contain information \n",
    "# these exist because of skipped page-numbers in case of double-lenght episodes\n",
    "drop_bad_htm_pages(df_TOS_raw)\n",
    "drop_bad_htm_pages(df_TNG_raw)\n",
    "drop_bad_htm_pages(df_DS9_raw)\n",
    "drop_bad_htm_pages(df_VOY_raw)\n",
    "drop_bad_htm_pages(df_ENT_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971c6fea",
   "metadata": {},
   "source": [
    "<a name=\"sep_lines_char\"></a>\n",
    "#### Seperating Lines per Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43368dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designing regex\n",
    "seperate_lines_regex = \"(Personal\\s+log|Captain's\\s+log|[A-Z]{2,} \\[OC\\]|Q:|[A-Z]{2,})(.+?(?=[A-Z]{2,}|Q:|[A-Z\\s0-9]{2,}\\s+\\[.+\\]|$))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4ecf70",
   "metadata": {},
   "source": [
    "**Explanation of the regex**\n",
    "\n",
    "Regex: ```(Personal\\s+log|Captain's\\s+log|[A-Z]{2,} \\[OC\\]|Q:|[A-Z]{2,})(.+?(?=[A-Z]{2,}|Q:|[A-Z\\s0-9]{2,}\\s+\\[.+\\]|$))```\n",
    "\n",
    "\n",
    "The Basic structure is the one of two capture groups:  \n",
    "\n",
    "Group 1: `(Personal\\s+log|Captain's\\s+log|[A-Z]{2,} \\[OC\\]|Q:|[A-Z]{2,})`\n",
    "\n",
    "This group consists of 5 different patterns that it will match ( `|` = or)\n",
    "- `Personal\\s+log` to match lines that start are a personal log entry, since those are not always preceeded by the talking character's name.\n",
    "- `Captain's\\s+log` to match lines that start are a captain's log entry, since those are not always preceeded by the talking character's name.\n",
    "- `[A-Z]{2,} \\[OC\\]` will match any character name (> 1 captial letters) that is proceeded by `[OC]`, which stands for \"over comm\". \n",
    "- `Q:` will match a the character Q speaking\n",
    "- `[A-Z]{2,}` will match any character name (> 1 captial letters)\n",
    "\n",
    "Group 2: `(.+?(?=[A-Z]{2,}|Q:|[A-Z\\s0-9]{2,}\\s+\\[.+\\]|$))`\n",
    "- The goal of group 2 is to capture the line a character said. It catches everything up to one of the specified lookahead patterns. \n",
    "- `.+?` will match everything until the patterns specified \n",
    "- `[A-Z]{2,}`, `Q:`, `[A-Z\\s0-9]{2,}\\s+\\[.+\\]` will match possible patterns for the name of the character speaking next.\n",
    "- `$` will match the end of a script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4da892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_names_and_lines(script_one_episode, regex=seperate_lines_regex):\n",
    "    \"\"\"Returns a tuple with (character_name, line_said) using the\n",
    "    episode script and regex given.\n",
    "    Arguments:\n",
    "        script_one_episode = scraped script of one episode\n",
    "        regex = the regex string to seperate lines (default=seperate_lines_regex)\n",
    "        \"\"\"\n",
    "    return re.findall(regex, script_one_episode)\n",
    "\n",
    "def get_characters_one_series(list_of_scripts_of_series,regex=seperate_lines_regex):\n",
    "    \"\"\"Returns a list with all characters speaking in a series.\n",
    "    Arguments:\n",
    "        lists_of_scripts_of_series = list containing scraped scripts of all episodes in a series\n",
    "        regex = the regex string to seperate lines (default=seperate_lines_regex)\"\"\"\n",
    "    \n",
    "    series_characters = set()\n",
    "    for script in list_of_scripts_of_series:\n",
    "        for line in find_names_and_lines(script, regex=regex):\n",
    "            character_name = line[0]  #accessing only the character name, captured in the first capture group\n",
    "            series_characters.add(character_name)\n",
    "            \n",
    "    return series_characters\n",
    "\n",
    "def collect_lines_per_character(list_of_scripts_of_series, regex=seperate_lines_regex):\n",
    "    \"\"\"Collects all lines of a character in a dictionary from\n",
    "    a list of scripts of a series. Output: dictionary of characters and their lines said in a list.\n",
    "    Arguments:\n",
    "        lists_of_scripts_of_series = list containing scraped scripts of all episodes in a series\n",
    "        regex = the regex string to seperate lines (default=seperate_lines_regex)\"\"\"\n",
    "    series_characters = get_characters_one_series(list_of_scripts_of_series, regex)\n",
    "    \n",
    "    # creates a dictionary with all characters of the series as keys\n",
    "    lines_per_character = {character:[] for character in series_characters}\n",
    "    \n",
    "    # iterates over the scripts to add individuals lines to one list per character\n",
    "    for script in list_of_scripts_of_series:\n",
    "        for line in find_names_and_lines(script, regex):\n",
    "            character_name = line[0]\n",
    "            line_content = line[1]\n",
    "            lines_per_character[character_name].append(line_content)\n",
    "    \n",
    "    return lines_per_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6382d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionaries of lines per characters in each series\n",
    "lines_per_character_TOS = collect_lines_per_character(df_TOS_raw.script)\n",
    "lines_per_character_TNG = collect_lines_per_character(df_TNG_raw.script)\n",
    "lines_per_character_DS9 = collect_lines_per_character(df_DS9_raw.script)\n",
    "lines_per_character_VOY = collect_lines_per_character(df_VOY_raw.script)\n",
    "lines_per_character_ENT = collect_lines_per_character(df_ENT_raw.script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca53325f",
   "metadata": {},
   "source": [
    "<a name=\"clean_up_lines\"></a>\n",
    "#### Clean up Lines\n",
    "\n",
    "The lines collected still contain some information that was not spoken by the characters themselves, such as stage directions, for example: `(The main door slams shut behind them.)`, which are always in between smooth parenthesis. Additionally characters in mirror universes/clones etc were designated with `OTHER`, which the line seperation regex cut off into the previous line. Locations are specified within squared brackets, e.g. `[BRIDGE]`. Lastly names with prefixes, for example `T'Pol` had their prefix cut off into the previous line, which in some cases could constitute data leakage (for example, since T'Pol only exists in ENT, the `T'`at the end of a line would be a clear predictor for Archer having said that line). \n",
    "\n",
    "The following functions clean the lines from these artefacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af332cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designing regex\n",
    "find_stage_directions_regex = \"\\(.+\\)\"\n",
    "find_other_regex = \"OTHER\"\n",
    "find_locations_regex = \"\\[.+\\]\"\n",
    "find_orphan_name_prefixes = \"[A-Z]'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952d528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stage_directions(line):\n",
    "    \"\"\"Removes text in parenthesis (stage directions) from a single line.\n",
    "    Arguments:\n",
    "        line = one line of dialog to clean.\"\"\"\n",
    "    for stage_direction in re.findall(find_stage_directions_regex, line):\n",
    "        line = line.replace(stage_direction, \"\")\n",
    "    return line\n",
    "\n",
    "def remove_semicolons(line):\n",
    "    \"\"\"Removes semicolons from a single line\n",
    "    Arguments:\n",
    "        line = one line of dialog to clean.\"\"\"\n",
    "    return line.replace(\":\", \"\")\n",
    "\n",
    "def remove_other(line):\n",
    "    \"\"\"Removes OTHER, signifying cloned/alternate universe characters from a single line.\n",
    "    Arguments:\n",
    "        line = one line of dialog to clean.\"\"\"\n",
    "    for other in re.findall(find_other_regex, line):\n",
    "        line = line.replace(other, \"\")\n",
    "    return line\n",
    "    \n",
    "def remove_locations(line):\n",
    "    \"\"\"Removes text in squared brackets [location information] from a single line.\n",
    "    Arguments:\n",
    "        line = one line of dialog to clean.\"\"\"\n",
    "    for location in re.findall(find_locations_regex, line):\n",
    "        line = line.replace(location, \"\")\n",
    "    return line   \n",
    "\n",
    "def remove_orphan_name_prefixes(line):\n",
    "    \"\"\"Removes orphaned name prefixes (e.g. \"O'\" if the next line was said by O'Brian).\n",
    "    Arguments:\n",
    "        line = one line of dialog to clean.\"\"\"\n",
    "    for orphan_name in re.findall(find_orphan_name_prefixes, line):\n",
    "        line = line.replace(orphan_name, \"\")\n",
    "    return line\n",
    "\n",
    "def clean_lines_per_character(dictionary_lines_per_character):\n",
    "    \"\"\"Combines the following cleaning function: remove_stage_directions,\n",
    "    remove_semicolons, remove_other, remove_locations, remove_orphan_name_prefixes and applies them\n",
    "    to all lines in a series dictionary.\n",
    "    Arguments:\n",
    "        dictionary_of_lines_per_character = dictionary with all lines of a character to iterate through.\"\"\"\n",
    "    cleaned_lines_per_character = {}\n",
    "    \n",
    "    # iterating over all lines in a series dictionary to apply cleaning functions\n",
    "    for character, lines_one_character in dictionary_lines_per_character.items():\n",
    "        cleaned_lines_one_character = []\n",
    "        for line in lines_one_character:\n",
    "            line = remove_stage_directions(line)\n",
    "            line = remove_semicolons(line)\n",
    "            line = remove_other(line)\n",
    "            line = remove_locations(line)\n",
    "            line = remove_orphan_name_prefixes(line)\n",
    "            line = line.strip(\" \")  # removes whitespace\n",
    "            line = line.strip(\";\")\n",
    "\n",
    "            cleaned_lines_one_character.append(line)\n",
    "\n",
    "        cleaned_lines_per_character[character] = cleaned_lines_one_character\n",
    "    \n",
    "    return cleaned_lines_per_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ddfc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_lines_per_character_TOS = clean_lines_per_character(lines_per_character_TOS)\n",
    "cleaned_lines_per_character_TNG = clean_lines_per_character(lines_per_character_TNG)\n",
    "cleaned_lines_per_character_DS9 = clean_lines_per_character(lines_per_character_DS9)\n",
    "cleaned_lines_per_character_VOY = clean_lines_per_character(lines_per_character_VOY)\n",
    "cleaned_lines_per_character_ENT = clean_lines_per_character(lines_per_character_ENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75acb0a",
   "metadata": {},
   "source": [
    "<a name=\"eda\"></a>\n",
    "## EDA\n",
    "\n",
    "**Section Overview:**\n",
    "- [Preparation of dataframes](#prep_df)\n",
    "- [Line Counts per Captain](#line_counts_per_captain)\n",
    "- [Count all words including common english words](#wordcount_no_stopwords)\n",
    "- [Count all words excluding common english words](#wordcount_with_stopwords)\n",
    "- [Wordclouds](#wordclouds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb268c",
   "metadata": {},
   "source": [
    "<a name=\"prep_df\"></a>\n",
    "### Preparation of dataframes\n",
    "\n",
    "In this section various dataframes are prepared for later use in modelling and other analysis. This includes a collection of all lines per each series, collections of all lines per captain and collections with modifications such as only lines with more than 5 words. \n",
    "This step of feature engineering was taken because neither model nor human can be expected to accurately predict whether Kirk or Picard said the line: \"Yes.\". \n",
    "\n",
    "The number of words in a line was extracted as a seperate feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c064747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines_one_series(cleaned_lines_per_character_series):\n",
    "    \"\"\"Function that gathers all lines from a series in one list.\n",
    "    Arguments:\n",
    "        cleaned_lines_per_character_series = dictionary of cleaned lines sorted by character.\"\"\"\n",
    "    lines_series = []\n",
    "    for key in cleaned_lines_per_character_series.keys():\n",
    "        lines_series.extend(cleaned_lines_per_character_series[key])\n",
    "    return lines_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect lines per series\n",
    "lines_TOS = get_lines_one_series(cleaned_lines_per_character_TOS)\n",
    "lines_TNG = get_lines_one_series(cleaned_lines_per_character_TNG)\n",
    "lines_DS9 = get_lines_one_series(cleaned_lines_per_character_DS9)\n",
    "lines_VOY = get_lines_one_series(cleaned_lines_per_character_VOY)\n",
    "lines_ENT = get_lines_one_series(cleaned_lines_per_character_ENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faead6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect lines per character: Picard\n",
    "# collecting lines within the TNG series\n",
    "lines_picard_TNG = cleaned_lines_per_character_TNG[\"PICARD\"]\n",
    "lines_picard_TNG.extend(cleaned_lines_per_character_TNG[\"PICARD [OC]\"])  #include lines were said over comm\n",
    "\n",
    "# adding lines from Picard in DS9 and ENT\n",
    "lines_picard = lines_picard_TNG\n",
    "lines_picard.extend(cleaned_lines_per_character_DS9[\"PICARD\"]) #include DS9 and ENT crossover episodes\n",
    "lines_picard.extend(cleaned_lines_per_character_ENT[\"PICARD\"])\n",
    "\n",
    "# collect lines per character: Kirk\n",
    "# collecting lines withing the TOS series\n",
    "lines_kirk_TOS = cleaned_lines_per_character_TOS[\"KIRK\"]\n",
    "lines_kirk_TOS.extend(cleaned_lines_per_character_TOS[\"KIRK [OC]\"]) \n",
    "\n",
    "# adding lines from Kirk in DS9 and ENT\n",
    "lines_kirk = lines_kirk_TOS\n",
    "lines_kirk.extend(cleaned_lines_per_character_DS9[\"KIRK\"])\n",
    "lines_kirk.extend(cleaned_lines_per_character_DS9[\"KIRK [OC]\"])\n",
    "lines_kirk.extend(cleaned_lines_per_character_ENT[\"KIRK\"])\n",
    "\n",
    "# collect lines per character: Sisko (speaks only in DS9)\n",
    "lines_sisko = cleaned_lines_per_character_DS9[\"SISKO\"]\n",
    "lines_sisko.extend(cleaned_lines_per_character_DS9[\"SISKO [OC]\"])\n",
    "\n",
    "# collect lines per character: Janeway (speaks only in VOY)\n",
    "lines_janeway = cleaned_lines_per_character_VOY[\"JANEWAY\"]\n",
    "lines_janeway.extend(cleaned_lines_per_character_VOY[\"JANEWAY [OC]\"])\n",
    "\n",
    "# collect lines per character: Archer (speaks only in ENT)\n",
    "lines_archer = cleaned_lines_per_character_ENT[\"ARCHER\"]\n",
    "lines_archer.extend(cleaned_lines_per_character_ENT[\"ARCHER [OC]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795a63af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out lines consisting only of numbers\n",
    "lines_picard = [line for line in lines_picard if type(line) != int]\n",
    "lines_kirk = [line for line in lines_kirk if type(line) != int]\n",
    "lines_sisko = [line for line in lines_sisko if type(line) != int]\n",
    "lines_janeway = [line for line in lines_janeway if type(line) != int]\n",
    "lines_archer = [line for line in lines_archer if type(line) != int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ae4c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe for each captain\n",
    "df_lines_picard = pd.DataFrame(lines_picard, columns=[\"line\"])\n",
    "df_lines_picard[\"character\"] = \"picard\"\n",
    "\n",
    "df_lines_kirk = pd.DataFrame(lines_kirk, columns=[\"line\"])\n",
    "df_lines_kirk[\"character\"] = \"kirk\"\n",
    "\n",
    "df_lines_sisko = pd.DataFrame(lines_sisko, columns=[\"line\"])\n",
    "df_lines_sisko[\"character\"] = \"sisko\"\n",
    "\n",
    "df_lines_janeway = pd.DataFrame(lines_janeway, columns=[\"line\"])\n",
    "df_lines_janeway[\"character\"] = \"janeway\"\n",
    "\n",
    "df_lines_archer = pd.DataFrame(lines_archer, columns=[\"line\"])\n",
    "df_lines_archer[\"character\"] = \"archer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65539be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating combined dataframes\n",
    "\n",
    "# lines of Kirk and Picard\n",
    "df_lines_kirk_picard = pd.concat([df_lines_picard, df_lines_kirk], axis=0)\n",
    "\n",
    "df_lines_kirk_picard.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "# lines of all captains\n",
    "df_lines_all_captains = pd.concat([df_lines_kirk_picard, df_lines_sisko, \n",
    "                                   df_lines_janeway, df_lines_archer], axis=0)\n",
    "\n",
    "df_lines_all_captains.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5ce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a filter function to select lines by number of words\n",
    "def get_lines_greater_x_words(dataframe_lines_character, x=5):\n",
    "    \"\"\"Gets lines greater than x words\n",
    "    Arguments:\n",
    "        dataframe_lines_character = pandas dataframe containing the lines said by one character\n",
    "        x = minimum number of words wanted in a line (default=5).\"\"\"\n",
    "    \n",
    "    dataframe_lines_greater_x_words = dataframe_lines_character.copy()\n",
    "    \n",
    "    for index, line in enumerate(dataframe_lines_character[\"line\"]):\n",
    "        number_of_words_in_line = len(line.split(\" \"))\n",
    "        \n",
    "        # drop lines with less than the amount of words specified\n",
    "        if ((number_of_words_in_line < x) | (len(line) <= 20)):\n",
    "            dataframe_lines_greater_x_words = dataframe_lines_greater_x_words.drop(index=index)\n",
    "    \n",
    "    return dataframe_lines_greater_x_words\n",
    "\n",
    "\n",
    "# function to add the counts of words into a new feature\n",
    "def add_word_count_to_df(dataframe_lines_character):\n",
    "    \"\"\"Adds a new column including the word count of a line.\n",
    "    Arguments:\n",
    "        dataframe_lines_character = pandas dataframe containing the lines said by one character.\"\"\"\n",
    "    \n",
    "    dataframe_lines_character_word_count = dataframe_lines_character.copy()\n",
    "    dataframe_lines_character_word_count[\"num_words\"] = np.nan\n",
    "    \n",
    "    # for each line, count the words, add the count into a new column\n",
    "    for index, line in zip(dataframe_lines_character.index, dataframe_lines_character[\"line\"]):\n",
    "        number_of_words_in_line = len(line.split(\" \"))\n",
    "        \n",
    "        dataframe_lines_character_word_count.loc[index,\"num_words\"] = number_of_words_in_line\n",
    "    \n",
    "    return dataframe_lines_character_word_count   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b84690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes with all lines with at least 5 words\n",
    "\n",
    "# combined dataframes\n",
    "df_lines_kirk_picard_5_words = get_lines_greater_x_words(df_lines_kirk_picard)\n",
    "df_lines_all_captains_5_words = get_lines_greater_x_words(df_lines_all_captains)\n",
    "\n",
    "# dataframes of individual captains\n",
    "df_lines_kirk_5_words = get_lines_greater_x_words(df_lines_kirk)\n",
    "df_lines_picard_5_words = get_lines_greater_x_words(df_lines_picard)\n",
    "df_lines_sisko_5_words = get_lines_greater_x_words(df_lines_sisko)\n",
    "df_lines_janeway_5_words = get_lines_greater_x_words(df_lines_janeway)\n",
    "df_lines_archer_5_words = get_lines_greater_x_words(df_lines_archer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13efac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding word counts as a seperate feature for lines >= 5 words\n",
    "\n",
    "# combined dataframes\n",
    "df_lines_kirk_picard_word_count = add_word_count_to_df(df_lines_kirk_picard_5_words)\n",
    "df_lines_all_captains_word_count = add_word_count_to_df(df_lines_all_captains_5_words)\n",
    "\n",
    "# dataframes of individual captains\n",
    "df_lines_kirk_word_count= add_word_count_to_df(df_lines_kirk_5_words)\n",
    "df_lines_picard_word_count = add_word_count_to_df(df_lines_picard_5_words)\n",
    "df_lines_sisko_word_count = add_word_count_to_df(df_lines_sisko_5_words)\n",
    "df_lines_janeway_word_count = add_word_count_to_df(df_lines_janeway_5_words)\n",
    "df_lines_archer_word_count = add_word_count_to_df(df_lines_archer_5_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e40a0a",
   "metadata": {},
   "source": [
    "<a name=\"totalwc_avg_num_words\"></a>\n",
    "#### Total Word Counts and Average Number of Words per Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf18e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the words in each line for all lines and all captains\n",
    "df_lines_all_captains_all_lines_word_count = add_word_count_to_df(df_lines_all_captains)\n",
    "\n",
    "# calculating the average word count per line\n",
    "total_number_of_words_per_captain = df_lines_all_captains_all_lines_word_count.groupby(\"character\").sum()\n",
    "total_number_of_lines_per_captain = df_lines_all_captains_all_lines_word_count.groupby(\"character\").count()\n",
    "\n",
    "average_lenght_of_line = (total_number_of_words_per_captain / total_number_of_lines_per_captain)[[\"num_words\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103c645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number_of_words_per_captain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ad397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_lenght_of_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73409ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(average_lenght_of_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91901beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a plot of average word count per line per captain\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# setting title parameters and title\n",
    "title_params = {\"font\":\"DIN Condensed\",\"verticalalignment\":\"baseline\",\n",
    "        \"size\":25,\"horizontalalignment\": \"center\"}\n",
    "\n",
    "plt.title(\"Average word count per line\", title_params)\n",
    "\n",
    "# create the bar chart object\n",
    "bar_chart = ax.barh(average_lenght_of_line.sort_values(\"num_words\",ascending=True).index, \n",
    "                    average_lenght_of_line.sort_values(\"num_words\",ascending=True).num_words, \n",
    "                    color=[\"#9a99ff\",\"#9a99ff\",\"#cc6698\",\"#cc6698\",\"#cc6698\"], edgecolor=\"black\")\n",
    "\n",
    "# adding text to the bar chart\n",
    "for bar, num_words in zip(ax.patches, average_lenght_of_line.sort_values(\"num_words\",ascending=True).num_words):\n",
    "    if num_words < np.mean(average_lenght_of_line).values: # text within the bar for bars below the mean\n",
    "        ax.text(bar.get_x()+bar.get_width()-1.8, bar.get_y()+bar.get_height()/2, round(num_words,2), \n",
    "            color = 'black', ha = 'left', va = 'center',  fontproperties={\"size\":20})\n",
    "    else: # text to the right of the bar for bars above the mean\n",
    "        ax.text(bar.get_x()+bar.get_width()+0.4, bar.get_y()+bar.get_height()/2, round(num_words,2), \n",
    "            color = 'black', ha = 'left', va = 'center',  fontproperties={\"size\":20})\n",
    "\n",
    "# change labels on the y-axis to capitalized captain names\n",
    "plt.yticks(font=\"DIN Condensed\",ticks=[0,1,2,3,4],labels=[\"Archer\",\"Kirk\",\"Sisko\",\"Picard\",\"Janeway\"],size=20)\n",
    "\n",
    "# change size of labels on the x-axis\n",
    "plt.xticks(size=15)\n",
    "\n",
    "# add vertical line\n",
    "plt.axvline(np.mean(average_lenght_of_line).values, **{\"c\":\"black\"})\n",
    "\n",
    "# add text for the mean\n",
    "ax.text(11.3, -1.5, u\"\\u03bc = 11.9\", fontproperties={\"size\":15, \"style\":\"italic\"})\n",
    "\n",
    "# set lenght of x axis\n",
    "plt.xlim(0,15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feff9d40",
   "metadata": {},
   "source": [
    "<a name=\"part_of_speech\"></a>\n",
    "#### Part of Speech Tagging\n",
    "\n",
    "William Shatner's performance as James T. Kirk using dramatic pauses is iconic. Whether these pauses are reflected in the script using more punctiation remains to be seen. In any case part of speech tagging might pick up on subtle differences in style of speaking. \n",
    "The following section uses the `nltk` module `pos_tag` to engineer grammatical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a3e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_part_of_speech_features(df_lines):\n",
    "    \"\"\"Function to apply a simple tokenizer (including punctuation) and part of speech tagging to \n",
    "    each line of a character. Returns the counts of parts of speech per line as added features \n",
    "    to the given dataframe.\n",
    "    Arguments:\n",
    "        df_lines = dataframe with lines to process\"\"\"\n",
    "    \n",
    "    tok = WordPunctTokenizer() # initialise a simple tokenizer that includes punctuation\n",
    "    \n",
    "    df_lines_pos = df_lines.copy()\n",
    "    \n",
    "    # iterate over the lines in the dataframe\n",
    "    for index, line in zip(df_lines_pos.index, df_lines_pos[\"line\"]):\n",
    "        \n",
    "        # create a list of part of speech items of the line\n",
    "        pos_features_per_line = [b for a,b in pos_tag(tok.tokenize(line))]\n",
    "\n",
    "        # iterate over part of speech items in one line\n",
    "        for pos_feature in pos_features_per_line:\n",
    "            \n",
    "            # check if the feature of that part of speech type already exists\n",
    "            if pos_feature in df_lines_pos.columns:\n",
    "                if df_lines_pos.loc[index,pos_feature] > 0:  #in case the type already occured in this line, add 1\n",
    "                    df_lines_pos.loc[index,pos_feature] += 1\n",
    "                else: # in case the part has not occured in this line yet, set the cell to 1\n",
    "                    df_lines_pos.loc[index,pos_feature] = 1\n",
    "            else: # create a new feature column and set it to one \n",
    "                df_lines_pos.loc[index,pos_feature] = 1\n",
    "                \n",
    "    return df_lines_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75b544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add part of speech tacking to the dataframes\n",
    "df_lines_kirk_picard_pos = extract_part_of_speech_features(df_lines_kirk_picard_word_count)\n",
    "df_lines_all_captains_pos = extract_part_of_speech_features(df_lines_all_captains_word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3582fffe",
   "metadata": {},
   "source": [
    "Getting part of speech tagging for the example line (for use in the presentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34525c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_example = pd.DataFrame([[\"What do you think, Counsellor?\"]], columns=[\"line\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7016b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_part_of_speech_features(pos_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb53448",
   "metadata": {},
   "source": [
    "<a name=\"perc_per_captain\"></a>\n",
    "#### Percentage of lines said by a captain in their series\n",
    "\n",
    "Which captain talks the most in their series, relative to other characters? (yes, it is Kirk). This section is a short interlude to calculate percentage of lines in a series said by its respective main captain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489242f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_total_lines_per_series(cleaned_lines_per_charcter_dict):\n",
    "    \"\"\"Counts total lines per series (that are not empty)\n",
    "    Arguments: \n",
    "        cleaned_lines_per_charcter_dict = Dictionary of collected lines per character of a series.\"\"\"\n",
    "    line_count_per_char = [len(lines) \n",
    "                           for lines in cleaned_lines_per_charcter_dict.values() \n",
    "                           if len(lines) > 0]\n",
    "    return sum(line_count_per_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ecedda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Couting total lines of all characters per series\n",
    "total_line_count_TOS = count_total_lines_per_series(cleaned_lines_per_character_TOS)\n",
    "total_line_count_TNG = count_total_lines_per_series(cleaned_lines_per_character_TNG)\n",
    "total_line_count_DS9 = count_total_lines_per_series(cleaned_lines_per_character_DS9)\n",
    "total_line_count_VOY = count_total_lines_per_series(cleaned_lines_per_character_VOY)\n",
    "total_line_count_ENT = count_total_lines_per_series(cleaned_lines_per_character_ENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f902c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating percentage of captain's lines per series\n",
    "perc_lines_kirk = round((len(lines_kirk_TOS)/ total_line_count_TOS)*100,1)\n",
    "perc_lines_picard = round((len(lines_picard_TNG)/ total_line_count_TNG)*100,1)\n",
    "perc_lines_sisko = round((len(lines_sisko)/ total_line_count_DS9)*100,1)\n",
    "perc_lines_janeway = round((len(lines_janeway)/ total_line_count_VOY)*100,1)\n",
    "perc_lines_archer = round((len(lines_archer)/ total_line_count_ENT)*100,1)\n",
    "\n",
    "\n",
    "# Creating overview table\n",
    "perc_lines_said_by_captains = pd.DataFrame([[len(lines_kirk_TOS),len(df_lines_kirk_5_words), perc_lines_kirk],\n",
    "              [len(lines_picard_TNG),len(df_lines_picard_5_words), perc_lines_picard],\n",
    "              [len(lines_sisko),len(df_lines_sisko_5_words), perc_lines_sisko],\n",
    "              [len(lines_janeway),len(df_lines_janeway_5_words), perc_lines_janeway],\n",
    "              [len(lines_archer),len(df_lines_archer_5_words), perc_lines_archer]],\n",
    "    index=[\"Kirk\", \"Picard\", \"Sisko\", \"Janeway\", \"Archer\"],\n",
    "    columns=[\"Lines total\", \"Lines ≥ 5 words\", \"% of lines in series\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c385337",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_lines_said_by_captains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5584752",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(perc_lines_said_by_captains[\"% of lines in series\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570d6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting percentage of lines said by its main captain\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "# creating the bar chart object\n",
    "bar_chart = ax.bar(perc_lines_said_by_captains.sort_values(\"% of lines in series\",ascending=False).index, \n",
    "                   perc_lines_said_by_captains.sort_values(\"% of lines in series\",ascending=False)[\"% of lines in series\"], \n",
    "                   color=[\"#cc6698\",\"#cc6698\",\"#9a99ff\",\"#9a99ff\",\"#9a99ff\"], edgecolor=\"black\")\n",
    "\n",
    "# adding numbers\n",
    "for bar, perc in zip(ax.patches, perc_lines_said_by_captains.sort_values(\"% of lines in series\",\n",
    "                                                            ascending=False)[\"% of lines in series\"]):\n",
    "    if perc > np.mean(perc_lines_said_by_captains[\"% of lines in series\"]): # number on top of the bar for > mean\n",
    "        ax.text(bar.get_x()+bar.get_width()/2, bar.get_y()+bar.get_height()+0.8,round(perc,2), \n",
    "            color = 'black', ha = 'center', va = 'center', size=20)\n",
    "    else: # number in the bar for < mean\n",
    "        ax.text(bar.get_x()+bar.get_width()/2, bar.get_y()+bar.get_height()-1.2,round(perc,2), \n",
    "            color = 'black', ha = 'center', va = 'center', size=20)\n",
    "\n",
    "# add title\n",
    "ax.set_title(\"Percentage of lines in a series said by its main captain\", title_params)\n",
    "\n",
    "# add horizontal line at mean\n",
    "ax.axhline(np.mean(perc_lines_said_by_captains[\"% of lines in series\"]), color=\"black\")\n",
    "\n",
    "# configure axis\n",
    "plt.yticks(size=20)\n",
    "plt.xticks(size=20)\n",
    "plt.ylim(0,35);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944f4488",
   "metadata": {},
   "source": [
    "<a name=\"wordcount_no_stopwords\"></a>\n",
    "#### Count all words including common english words\n",
    "\n",
    "This section determines the top 10 words said by each captain, including common English words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43885d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_cvec(lines, cvec):\n",
    "    \"\"\"Fit a vectorizer to a set of lines and return a dataframe of the tokenized\n",
    "    lines.\n",
    "    Arguments:\n",
    "        lines = list of lines said by one character\n",
    "        cvec = CountVectorizer instances used (Default=cvec_with_stopwords).\"\"\"\n",
    "    cvec_all = cvec\n",
    "    lines_sparse_matrix = cvec_all.fit_transform(lines)\n",
    "    df = pd.DataFrame(lines_sparse_matrix.toarray(), columns=cvec_all.get_feature_names())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19964751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create basic count vectorizer, no stopwords\n",
    "cvec_no_stopwords = CountVectorizer(input = \"content\",    \n",
    "                       encoding = \"utf-8\",   \n",
    "                       decode_error = \"strict\",\n",
    "                       strip_accents = None,    \n",
    "                       lowercase = True,\n",
    "                       token_pattern = \"\\s(\\w+)\\s\", #at least 1 word character in between two space characters\n",
    "                       stop_words = None,  \n",
    "                       ngram_range=(1,1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af778b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the count vectorizer to all indiv captains dataframes\n",
    "df_simple_wordcount_incl_common_picard = get_dataframe_cvec(lines_picard,cvec_no_stopwords)\n",
    "df_simple_wordcount_incl_common_kirk = get_dataframe_cvec(lines_kirk,cvec_no_stopwords)\n",
    "df_simple_wordcount_incl_common_sisko = get_dataframe_cvec(lines_sisko,cvec_no_stopwords)\n",
    "df_simple_wordcount_incl_common_janeway = get_dataframe_cvec(lines_janeway,cvec_no_stopwords)\n",
    "df_simple_wordcount_incl_common_archer = get_dataframe_cvec(lines_archer,cvec_no_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9e41bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating tables of top 10 words per captain\n",
    "word_count_picard_st = pd.DataFrame(df_simple_wordcount_incl_common_picard.sum(axis=0).sort_values(\n",
    "    ascending=False).head(10), \n",
    "             columns=[\"Wordcount Picard\"])\n",
    "\n",
    "word_count_kirk_st = pd.DataFrame(df_simple_wordcount_incl_common_kirk.sum(axis=0).sort_values(\n",
    "    ascending=False).head(10),\n",
    "             columns=[\"Wordcount Kirk\"])\n",
    "\n",
    "word_count_sisko_st = pd.DataFrame(df_simple_wordcount_incl_common_sisko.sum(axis=0).sort_values(\n",
    "    ascending=False).head(10),\n",
    "             columns=[\"Wordcount Sisko\"])\n",
    "\n",
    "word_count_janeway_st = pd.DataFrame(df_simple_wordcount_incl_common_janeway.sum(axis=0).sort_values(\n",
    "    ascending=False).head(10),\n",
    "             columns=[\"Wordcount Janeway\"])\n",
    "\n",
    "word_count_archer_st = pd.DataFrame(df_simple_wordcount_incl_common_archer.sum(axis=0).sort_values(\n",
    "    ascending=False).head(10),\n",
    "             columns=[\"Wordcount Archer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b943f07",
   "metadata": {},
   "source": [
    "<a name=\"analysing_freq_v_common\"></a>\n",
    "#### Analysing frequency of very common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb47cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for words in top 10 all captains have in common\n",
    "set(word_count_archer_st.index\n",
    "   ).intersection(set(word_count_janeway_st.index)\n",
    "                 ).intersection(set(word_count_kirk_st.index)\n",
    "                                                ).intersection(set(word_count_picard_st.index)\n",
    "                                                              ).intersection(set(word_count_sisko_st.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf8019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe including counts of top words by all captains\n",
    "top_words_all_char = ['a', 'i', 'of', 'the', 'to', 'you']\n",
    "\n",
    "common_words_allc = pd.DataFrame([[word_count_kirk_st.loc[\"a\", \"Wordcount Kirk\"], word_count_kirk_st.loc[\"i\", \"Wordcount Kirk\"],\n",
    "            word_count_kirk_st.loc[\"of\", \"Wordcount Kirk\"], word_count_kirk_st.loc[\"the\", \"Wordcount Kirk\"],\n",
    "            word_count_kirk_st.loc[\"to\", \"Wordcount Kirk\"], word_count_kirk_st.loc[\"you\", \"Wordcount Kirk\"]],\n",
    "              \n",
    "              [word_count_picard_st.loc[\"a\", \"Wordcount Picard\"], word_count_picard_st.loc[\"i\", \"Wordcount Picard\"],\n",
    "            word_count_picard_st.loc[\"of\", \"Wordcount Picard\"], word_count_picard_st.loc[\"the\", \"Wordcount Picard\"],\n",
    "            word_count_picard_st.loc[\"to\", \"Wordcount Picard\"], word_count_picard_st.loc[\"you\", \"Wordcount Picard\"]],\n",
    "              \n",
    "              [word_count_sisko_st.loc[\"a\", \"Wordcount Sisko\"], word_count_sisko_st.loc[\"i\", \"Wordcount Sisko\"],\n",
    "            word_count_sisko_st.loc[\"of\", \"Wordcount Sisko\"], word_count_sisko_st.loc[\"the\", \"Wordcount Sisko\"],\n",
    "            word_count_sisko_st.loc[\"to\", \"Wordcount Sisko\"], word_count_sisko_st.loc[\"you\", \"Wordcount Sisko\"]],\n",
    "              \n",
    "              [word_count_janeway_st.loc[\"a\", \"Wordcount Janeway\"], word_count_janeway_st.loc[\"i\", \"Wordcount Janeway\"],\n",
    "            word_count_janeway_st.loc[\"of\", \"Wordcount Janeway\"], word_count_janeway_st.loc[\"the\", \"Wordcount Janeway\"],\n",
    "            word_count_janeway_st.loc[\"to\", \"Wordcount Janeway\"], word_count_janeway_st.loc[\"you\", \"Wordcount Janeway\"]],\n",
    "              \n",
    "              [word_count_archer_st.loc[\"a\", \"Wordcount Archer\"], word_count_archer_st.loc[\"i\", \"Wordcount Archer\"],\n",
    "            word_count_archer_st.loc[\"of\", \"Wordcount Archer\"], word_count_archer_st.loc[\"the\", \"Wordcount Archer\"],\n",
    "            word_count_archer_st.loc[\"to\", \"Wordcount Archer\"], word_count_archer_st.loc[\"you\", \"Wordcount Archer\"]]\n",
    "             ], index=[\"Kirk\", \"Picard\", \"Sisko\", \"Janeway\", \"Archer\"], columns = top_words_all_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show total counts of very common words\n",
    "common_words_allc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd19dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of percentage of very common words\n",
    "common_words_perc = common_words_allc.apply(lambda x: x/perc_lines_said_by_captains[\"Lines total\"][x.name], \n",
    "                                            axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa25ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a20c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot percentages of very common words as stacked barchart per captain\n",
    "fig, ax = plt.subplots(edgecolor=\"black\")\n",
    "\n",
    "bottom_added = 0\n",
    "ax.bar(common_words_perc.index, common_words_perc.a, label=\"a\", color=\"#9a99ff\", \n",
    "       edgecolor=\"black\")\n",
    "bottom_added = common_words_perc.a.copy()\n",
    "ax.bar(common_words_perc.index, common_words_perc.i, bottom=bottom_added, label=\"i\", \n",
    "       color=\"#ffcc9a\", edgecolor=\"black\")\n",
    "bottom_added += common_words_perc.i\n",
    "ax.bar(common_words_perc.index, common_words_perc.of, bottom=bottom_added, label=\"of\", \n",
    "       color=\"#cc6698\", edgecolor=\"black\")\n",
    "bottom_added += common_words_perc.of\n",
    "ax.bar(common_words_perc.index, common_words_perc.the, bottom=bottom_added, label=\"the\", \n",
    "       color=\"#ff9900\", edgecolor=\"black\")\n",
    "bottom_added += common_words_perc.the\n",
    "ax.bar(common_words_perc.index, common_words_perc.to, bottom=bottom_added, label=\"to\", \n",
    "       color=\"#89DCB1\", edgecolor=\"black\")\n",
    "bottom_added += common_words_perc.to\n",
    "ax.bar(common_words_perc.index, common_words_perc.you, bottom=bottom_added, label=\"you\", \n",
    "       color=\"#869CD6\", edgecolor=\"black\")\n",
    "bottom_added += common_words_perc.you\n",
    "\n",
    "# chance sizes of axis labels\n",
    "plt.xticks(size=20)\n",
    "plt.yticks(size=20)\n",
    "\n",
    "# add title\n",
    "plt.title(\"Normalized Frequency of very common words\", size=20)\n",
    "\n",
    "# add legend\n",
    "plt.legend(loc=[1.05,0], fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79599fb4",
   "metadata": {},
   "source": [
    "<a name=\"wordcount_with_stopwords\"></a>\n",
    "#### Count all words excluding common english words\n",
    "\n",
    "This section determines the top 10 words said by each captain, excluding common English words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dcc32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a basic CountVectorizer instance with english stopwords\n",
    "cvec_with_stopwords = CountVectorizer(input = \"content\",    \n",
    "                       encoding = \"utf-8\",   \n",
    "                       decode_error = \"strict\",\n",
    "                       strip_accents = None,    \n",
    "                       lowercase = True,        \n",
    "                       token_pattern = \"\\s(\\w{2,})\\s\", \n",
    "                       stop_words = \"english\",\n",
    "                       ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d451cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting words excluding stop words\n",
    "df_simple_wordcount_excl_common_picard = get_dataframe_cvec(lines_picard, cvec_with_stopwords)\n",
    "df_simple_wordcount_excl_common_kirk = get_dataframe_cvec(lines_kirk, cvec_with_stopwords)\n",
    "df_simple_wordcount_excl_common_sisko = get_dataframe_cvec(lines_sisko, cvec_with_stopwords)\n",
    "df_simple_wordcount_excl_common_janeway = get_dataframe_cvec(lines_janeway, cvec_with_stopwords)\n",
    "df_simple_wordcount_excl_common_archer = get_dataframe_cvec(lines_archer, cvec_with_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37602ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting dataframes of top 10 words\n",
    "top10_words_picard = pd.DataFrame(df_simple_wordcount_excl_common_picard.sum(axis=0).sort_values(\n",
    "    ascending=False).head(10), columns=[\"Wordcount Picard\"])\n",
    "top10_words_kirk = pd.DataFrame(df_simple_wordcount_excl_common_kirk.sum(axis=0).sort_values(\n",
    "    ascending=False).head(10),columns=[\"Wordcount Kirk\"])\n",
    "top10_words_sisko = pd.DataFrame(df_simple_wordcount_excl_common_sisko.sum(axis=0).sort_values(\n",
    "    ascending=False).head(10), columns=[\"Wordcount Sisko\"])\n",
    "top10_words_janeway = pd.DataFrame(df_simple_wordcount_excl_common_janeway.sum(axis=0).sort_values(\n",
    "    ascending=False).head(10), columns=[\"Wordcount Janeway\"])\n",
    "top10_words_archer = pd.DataFrame(df_simple_wordcount_excl_common_archer.sum(axis=0).sort_values(\n",
    "    ascending=False).head(10), columns=[\"Wordcount Archer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442d18f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_words_picard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff18a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top10_words_kirk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7559efea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top10_words_sisko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5819efd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top10_words_janeway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c63417a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top10_words_archer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d2143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create wordcount dataframes for all series data\n",
    "df_simple_wordcount_excl_common_TOS = get_dataframe_cvec(lines_TOS, cvec_with_stopwords)\n",
    "df_simple_wordcount_excl_common_TNG = get_dataframe_cvec(lines_TNG, cvec_with_stopwords)\n",
    "df_simple_wordcount_excl_common_DS9 = get_dataframe_cvec(lines_DS9, cvec_with_stopwords)\n",
    "df_simple_wordcount_excl_common_VOY = get_dataframe_cvec(lines_VOY, cvec_with_stopwords)\n",
    "df_simple_wordcount_excl_common_ENT = get_dataframe_cvec(lines_ENT, cvec_with_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc21a5b8",
   "metadata": {},
   "source": [
    "<a name=\"wordclouds\"></a>\n",
    "#### Creating Wordclouds\n",
    "\n",
    "Using the word counts (excl. common English words) word clouds for each captain can be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df8cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_wordcloud(data, color = \"white\", image=None):\n",
    "    \"\"\"Creates a wordcloud from a cvec dataframe. \n",
    "    \n",
    "    Arguments:\n",
    "        data = dataframe with tokenized text\n",
    "        color = background color (default: white)\n",
    "        image = image color and crop the wordcloud\"\"\"\n",
    "    counts_per_word = data.sum(axis=0)\n",
    "    \n",
    "    wordcloud_text = \"\"\n",
    "    \n",
    "    # iterating over words and their frequency\n",
    "    for word, count in zip(counts_per_word.index, counts_per_word):\n",
    "        multiplied_word = (word + \" \") * count  # multiplying the word by its frequency\n",
    "        wordcloud_text += multiplied_word # creating a string to be parsed by the WordCloud method\n",
    "\n",
    "    wordcloud = WordCloud(\n",
    "                      background_color=color,\n",
    "                      width=2500,\n",
    "                      height=2000,\n",
    "                      max_words=1000,\n",
    "                      stopwords= set(\"la\"),\n",
    "                      collocations=False,\n",
    "                      mask=image,  # using an image with a white background as a mask\n",
    "                     ).generate(wordcloud_text)\n",
    "    \n",
    "    # determining wordcolor from an image\n",
    "    image_colors = ImageColorGenerator(image)\n",
    "    \n",
    "    plt.figure(1,figsize=(13, 13))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.imshow(wordcloud.recolor(color_func=image_colors),interpolation=\"bilinear\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaad5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "picard_coloring = iio.imread(\"/Users/tjanif/Desktop/KirkvPicard_Material/pictures/picard.png\")\n",
    "make_wordcloud(df_simple_wordcount_excl_common_picard, image=picard_coloring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3ce0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "kirk_coloring = iio.imread(\"/Users/tjanif/Desktop/KirkvPicard_Material/pictures/kirk2.jpeg\")\n",
    "make_wordcloud((df_simple_wordcount_excl_common_kirk), image=kirk_coloring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12686162",
   "metadata": {},
   "outputs": [],
   "source": [
    "sisko_coloring = iio.imread(\"/Users/tjanif/Desktop/KirkvPicard_Material/pictures/sisko.jpeg\")\n",
    "make_wordcloud((df_simple_wordcount_excl_common_sisko), image=sisko_coloring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2dc4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "janeway_coloring = iio.imread(\"/Users/tjanif/Desktop/KirkvPicard_Material/pictures/janeway3.jpeg\")\n",
    "make_wordcloud((df_simple_wordcount_excl_common_janeway), image=janeway_coloring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af6291",
   "metadata": {},
   "outputs": [],
   "source": [
    "archer_coloring = iio.imread(\"/Users/tjanif/Desktop/KirkvPicard_Material/pictures/archer_bad_cropped.png\")\n",
    "make_wordcloud((df_simple_wordcount_excl_common_archer), image=archer_coloring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f6687f",
   "metadata": {},
   "source": [
    "## Basic Models\n",
    "\n",
    "For this classification problem a series of basic models were tested only against the count of words in a given line to get an overview of how different models perform on the data given, especially since the occurence of certain words, for example \"Spock\" will most likely be highly predictive of Kirk having said that line. \n",
    "\n",
    "Modelling was only done on line with at least 5 words.\n",
    "The Basic models were run both on a binary classification (Kirk vs Picard) and on a multiclass problem (all captains), subsequent advanced models were only tested on the multiclass task.\n",
    "\n",
    "**Section Overview:**\n",
    "- [Preparing Data for Basic Modelling](#prep_base_data)\n",
    "    - [Baseline Accuracy](#baseline)\n",
    "    - [Train/Test Splits](#ttsplits)\n",
    "- [Create Pipelines](#create_pipelines)\n",
    "    - [Create Vectorizers](#create_vectorizers)\n",
    "    - [Create Models](#create_models)\n",
    "    - [Create Pipelines with Param-Grids](#create_pipelines_2)\n",
    "- [Fitting Basic Models](#basic_models)\n",
    "    - [Modelling Functions](#modelling_functions)\n",
    "    - [Fit Basic Models (Vectorized Lines) for Kirk vs Picard](#fit_basic_models_kvp)\n",
    "    - [Fit Basic Models (Vectorized Lines) for all captains](#fit_basic_models_capt)\n",
    "    \n",
    "    \n",
    "- [Evaluating Basic Models](#eval_basic_models)\n",
    "    - [Model evaluation functions](#eval_functions)\n",
    "    - [Kirk vs Picard](#kirkvpicard_eval)\n",
    "        - [Overview](#kirkvpicard_overview_eval)\n",
    "        - [Logistic Regression -  Kirk vs Picard](#kirkvpicard_logreg)\n",
    "        - [Decision Tree -  Kirk vs Picard](#kirkvpicard_dectree)\n",
    "        - [Bernoulli Native Bayes - Kirk vs Picard](#kirkvpicard_bayes)\n",
    "        - [Random Forest - Kirk vs Picard](#krikvpicard_random_forest)\n",
    "        - [Logistic Regression + tfidf - Kirk vs Picard](#krikvpicard_logreg_tfidf)\n",
    "        - [Decision Tree + tfidf - Kirk vs Picard](#krikvpicard_dectree_tfidf)\n",
    "        - [Bernoulli Naive Bayes + tfidf - Kirk vs Picard](#krikvpicard_bayes_tfidf)\n",
    "    - [All Captains](#allc_eval)\n",
    "        - [Overview](#allc_overview_eval)\n",
    "        - [Logistic Regression -  All Captains](#allc_logreg)\n",
    "        - [Decision Tree -   All Captains](#allc_dectree)\n",
    "        - [Bernoulli Native Bayes -  All Captains](#allc_bayes)\n",
    "        - [Random Forest -  All Captains](#allc_random_forest)\n",
    "        - [Logistic Regression + tfidf -  All Captains](#allc_logreg_tfidf)\n",
    "        - [Decision Tree + tfidf -  All Captains](#allc_dectree_tfidf)\n",
    "        - [Bernoulli Naive Bayes + tfidf -  All Captains](#allc_bayes_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf5f0cb",
   "metadata": {},
   "source": [
    "<a name=\"prep_base_data\"></a>\n",
    "### Preparing Data for Basic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30c2b12",
   "metadata": {},
   "source": [
    "<a name=\"baseline\"></a>\n",
    "#### Baseline Accuracy\n",
    "\n",
    "The models will compete with the baseline accuracy, which is the proportion of the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed2bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picard vs Kirk lines with at least 5 words\n",
    "print(\"Picard vs Kirk, lines with at least 5 words\")\n",
    "print(df_lines_kirk_picard_5_words[\"character\"].value_counts(normalize=True))\n",
    "print(\"..................\")\n",
    "# All captains lines with at least 5 words\n",
    "norm_line_count_allc = df_lines_all_captains_5_words[\"character\"].value_counts(normalize=True)\n",
    "line_count_allc = df_lines_all_captains_5_words[\"character\"].value_counts(normalize=False)\n",
    "print(\"All captains, lines with at least 5 words\")\n",
    "print(df_lines_all_captains_5_words[\"character\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e659796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of lines with at least 5 words\n",
    "sum(line_count_allc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edde43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline plot\n",
    "fig, ax = plt.subplots(figsize=(2.5,5))\n",
    "\n",
    "# add title\n",
    "ax.set_title(\"Class Balance\", size=25)\n",
    "\n",
    "# create bar chart\n",
    "ax.bar(\"a\", norm_line_count_allc.picard, color=\"#9a99ff\", edgecolor=\"black\",label=\"Picard\")\n",
    "offset_bottom = norm_line_count_allc.picard\n",
    "ax.bar(\"a\", norm_line_count_allc.janeway, bottom=offset_bottom, color=\"#ffcc9a\",edgecolor=\"black\",label=\"Janeway\")\n",
    "offset_bottom += norm_line_count_allc.janeway\n",
    "ax.bar(\"a\", norm_line_count_allc.kirk, bottom=offset_bottom, color=\"#cc6698\", edgecolor=\"black\",label=\"Kirk\")\n",
    "offset_bottom += norm_line_count_allc.kirk\n",
    "ax.bar(\"a\", norm_line_count_allc.sisko, bottom=offset_bottom, color=\"#156FA2\", edgecolor=\"black\",label=\"Sisko\")\n",
    "offset_bottom += norm_line_count_allc.sisko\n",
    "ax.bar(\"a\", norm_line_count_allc.archer, bottom=offset_bottom, color=\"#087F8C\", edgecolor=\"black\",label=\"Archer\")\n",
    "offset_bottom += norm_line_count_allc.archer\n",
    "\n",
    "# adding percentages and total counts of lines to bar charts\n",
    "for bar,value in zip(ax.patches, zip(norm_line_count_allc.values, line_count_allc)):\n",
    "    \n",
    "    ax.text(bar.get_x()+bar.get_width()/2, bar.get_y()+bar.get_height()/2, \n",
    "            f\"{int(round(value[0],2)*100)}% ({round(value[1],4)})\",\n",
    "            color = 'black', ha = 'center', va = 'center', size=20)\n",
    "\n",
    "# add captain names next to bar chart    \n",
    "for bar,index in zip(ax.patches, [\"Picard\", \"Janeway\", \"Kirk\", \"Sisko\", \"Archer\"]):\n",
    "    \n",
    "    ax.text(bar.get_x()+bar.get_width()+0.1, bar.get_y()+bar.get_height()/2, index,\n",
    "            color = 'black', ha = 'left', va = 'center', size=20)\n",
    "\n",
    "# remove box and xticks\n",
    "ax.set_xticks(\" \")\n",
    "ax.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daf80ab",
   "metadata": {},
   "source": [
    "<a name=\"ttsplits\"></a>\n",
    "#### Train/Test Splits for Basic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c922fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a train-test split of 80 to 20 %\n",
    "def creating_train_test_splits(df_X_y, test_size=0.2):\n",
    "    \"\"\"Function to create a stratified train-test-split from a dataframe with the first column \n",
    "    continaing predictors, the second column containing the target.\n",
    "    Arguments:\n",
    "        df_X_y = dataframe with the data as specified above.\n",
    "        test_size = relative size of the test set (default=0.2)\"\"\"\n",
    "    X = df_X_y.iloc[:,0]\n",
    "    y = df_X_y.iloc[:,1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=23, stratify=y)\n",
    "    \n",
    "    list_of_datasets = [X_train, y_train, X_test, y_test]\n",
    "    \n",
    "    # prints the shapes as quality control\n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    \n",
    "    return list_of_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3293390",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_list_split_kirk_picard = creating_train_test_splits(df_lines_kirk_picard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e125efee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_list_split_kirk_picard_5_words = creating_train_test_splits(df_lines_kirk_picard_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b50aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_list_split_kirk_picard_word_count = creating_train_test_splits(df_lines_kirk_picard_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a4dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_list_split_all_capt = creating_train_test_splits(df_lines_all_captains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d5676",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_list_split_all_capt_5_words = creating_train_test_splits(df_lines_all_captains_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d868a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_list_split_all_capt_word_count = creating_train_test_splits(df_lines_all_captains_word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3300624c",
   "metadata": {},
   "source": [
    "<a name=\"create_pipelines\"></a>\n",
    "### Create Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eae8c2e",
   "metadata": {},
   "source": [
    "<a name=\"create_vectorizers\"></a>\n",
    "#### Create Vectorizers\n",
    "\n",
    "Vectorizers to be used to do basic modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f751e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words = \"english\",     \n",
    "                       token_pattern=\"\\s(\\w{2,})\\s\", \n",
    "                       ngram_range =(1,1))\n",
    "                       #max_features = 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1999fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer(stop_words = \"english\",  \n",
    "                       token_pattern=\"\\s(\\w{2,})\\s\",  \n",
    "                       ngram_range=(1,1))\n",
    "                       #max_features = 50000) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c38429",
   "metadata": {},
   "source": [
    "<a name=\"create_models\"></a>\n",
    "#### Create Models\n",
    "\n",
    "Models to be used in basic modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf95635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=2000, solver=\"liblinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4971b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernoulliNB =  naive_bayes.BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7337a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomialNB =  naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff41af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_classifier = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8ab6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_classifier = RandomForestClassifier(n_estimators = 2000, \n",
    "                                                  criterion=\"gini\", \n",
    "                                                  n_jobs=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d66a65c",
   "metadata": {},
   "source": [
    "<a name=\"create_pipelines_2\"></a>\n",
    "#### Create Pipelines with Param-Grids\n",
    "\n",
    "A small grid search was used to tune hyperparameters. Since these models were only preliminary, computationally expensive searches were not deemed necessary at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8352a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_logreg = Pipeline([\n",
    "    ('vect', cvec),\n",
    "    ('logreg', logreg)\n",
    "])\n",
    "\n",
    "param_grid_logreg = {\n",
    "                \"vect__max_df\" : [.8, .9, 1.0],\n",
    "                \"logreg__penalty\" : [\"l1\", \"l2\"],\n",
    "                \"logreg__C\": np.logspace(-4, 4, 10)}\n",
    "\n",
    "gs_logreg = GridSearchCV(pipe_logreg, param_grid_logreg, n_jobs=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127b475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dectree = Pipeline([\n",
    "    ('vect', cvec),\n",
    "    ('DecTree', decision_tree_classifier)\n",
    "])\n",
    "\n",
    "param_grid_dectree = {\"vect__max_df\" : [.8, .9, 1.0],\n",
    "              \"DecTree__max_depth\" : np.linspace(20,80,4, dtype=int),\n",
    "              \"DecTree__min_samples_split\": np.linspace(2, 10, 5, dtype=int),\n",
    "              \"DecTree__min_samples_leaf\": np.linspace(2, 10, 5, dtype=int)}\n",
    "\n",
    "gs_dectree = GridSearchCV(pipe_dectree, param_grid_dectree, n_jobs=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef9b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_bayes = Pipeline([\n",
    "    ('vect', cvec),\n",
    "    ('BernoulliNB', bernoulliNB)\n",
    "])\n",
    "\n",
    "param_grid_bayes = {\"vect__max_df\" : [1.0],\n",
    "            \"BernoulliNB__alpha\" : [1.0]}\n",
    "\n",
    "gs_bayes = GridSearchCV(pipe_bayes, param_grid_bayes, n_jobs=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381330f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_random_forest = Pipeline([\n",
    "    ('vect', cvec),\n",
    "    ('Forest', random_forest_classifier)\n",
    "])\n",
    "\n",
    "param_grid_forest = {\n",
    "              \"Forest__max_depth\" : np.linspace(0,50,10, dtype=int)}\n",
    "\n",
    "gs_forest = GridSearchCV(pipe_random_forest, param_grid_forest, n_jobs=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25da9c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_bayes = Pipeline([\n",
    "    ('vect', cvec),\n",
    "    ('MultinomialNB', multinomialNB)\n",
    "])\n",
    "\n",
    "param_grid_bayes = {\"vect__max_df\" : [.8, .9, 1.0],\n",
    "            \"MultinomialNB__alpha\" : np.linspace(0.0,1.0,4)}\n",
    "\n",
    "gs_bayes_multi = GridSearchCV(pipe_bayes, param_grid_bayes, n_jobs=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f38c1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_logreg_tvec = Pipeline([\n",
    "    ('vect', tvec),\n",
    "    ('logreg', logreg)\n",
    "])\n",
    "\n",
    "param_grid_logreg = {\n",
    "                \"vect__max_df\" : [.8, .9, 1.0],\n",
    "                \"logreg__penalty\" : [\"l1\", \"l2\"],\n",
    "                \"logreg__C\": np.logspace(-4, 4, 10)}\n",
    "\n",
    "gs_logreg_tvec = GridSearchCV(pipe_logreg, param_grid_logreg, n_jobs=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960d9703",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dectree = Pipeline([\n",
    "    ('vect', tvec),\n",
    "    ('DecTree', decision_tree_classifier)\n",
    "])\n",
    "\n",
    "param_grid_dectree = {\"vect__max_df\" : [.8, .9, 1.0],\n",
    "              \"DecTree__max_depth\" : np.linspace(20,80,4, dtype=int),\n",
    "              \"DecTree__min_samples_split\": np.linspace(2, 10, 5, dtype=int),\n",
    "              \"DecTree__min_samples_leaf\": np.linspace(2, 10, 5, dtype=int)}\n",
    "\n",
    "gs_dectree_tvec = GridSearchCV(pipe_dectree, param_grid_dectree, n_jobs=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e69231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_bayes = Pipeline([\n",
    "    ('vect', tvec),\n",
    "    ('BernoulliNB', bernoulliNB)\n",
    "])\n",
    "\n",
    "param_grid_bayes = {\"vect__max_df\" : [.8, .9, 1.0],\n",
    "              \"BernoulliNB__alpha\" : np.linspace(0.0,1.0,4)}\n",
    "\n",
    "gs_bayes_tvec = GridSearchCV(pipe_bayes, param_grid_bayes, n_jobs=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c459c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_bayes = Pipeline([\n",
    "    ('vect', tvec),\n",
    "    ('MultinomialNB', multinomialNB)\n",
    "])\n",
    "\n",
    "param_grid_bayes = {\"vect__max_df\" : [.8, .9, 1.0],\n",
    "              \"MultinomialNB__alpha\" : np.linspace(0.0,1.0,4)}\n",
    "\n",
    "gs_bayes_tvec_multi = GridSearchCV(pipe_bayes, param_grid_bayes, n_jobs=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9b598b",
   "metadata": {},
   "source": [
    "<a name=\"basic_models\"></a>\n",
    "### Fitting Basic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89c8766",
   "metadata": {},
   "source": [
    "<a name=\"modelling_functions\"></a>\n",
    "#### Modelling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61218f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pipeline(pipe, X_train, y_train):\n",
    "    \"\"\"Fits a pipeline.\n",
    "    Arguments:\n",
    "        pipe = pipeline to fit\n",
    "        X_train = predictors training set\n",
    "        y_train = target training set.\"\"\"\n",
    "    pipe.fit(X_train,y_train)\n",
    "\n",
    "def get_scores(fitted_model, X_train, y_train, X_test, y_test, cv=5):\n",
    "    \"\"\"Gets Training/Mean Cross Val/Testing score for a fitted model and a provided set of train/test data.\n",
    "    Arguments:\n",
    "        fitted_model = model that has been fitted\n",
    "        X_train, y_train, X_test, y_test = training predictors/target as well as testing predictors/target\n",
    "        cv = number of cross-validation folds (default=5)\"\"\"\n",
    "    \n",
    "    cv_scores = cross_val_score(fitted_model, X_train, y_train, cv=cv)\n",
    "\n",
    "    print(\"Training Score:\", fitted_model.score(X_train, y_train))\n",
    "    print(\"Mean Cross Val Score:\", cv_scores.mean())\n",
    "    print(\"Testing Score:\", fitted_model.score(X_test, y_test))\n",
    "    \n",
    "    return (fitted_model.score(X_train, y_train), cv_scores.mean(), fitted_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d5fc16",
   "metadata": {},
   "source": [
    "<a name=\"fit_basic_models_kvp\"></a>\n",
    "#### Fit Basic Models (Vectorized Lines) for Kirk vs Picard\n",
    "- using the above Vectorizers (CountVectorizer and Tf-idf)\n",
    "- using the above models (LogisticRegression, DecisionTree, Bernoulli Native Bayes, RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087a68df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pipeline(gs_logreg, tt_list_split_kirk_picard_5_words[0], tt_list_split_kirk_picard_5_words[1])\n",
    "logreg_kp = gs_logreg.best_estimator_\n",
    "logreg_kp_scores = get_scores(logreg_kp, *tt_list_split_kirk_picard_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pipeline(gs_dectree, tt_list_split_kirk_picard_5_words[0], tt_list_split_kirk_picard_5_words[1])\n",
    "dectree_kp = gs_dectree.best_estimator_\n",
    "dectree_kp_scores = get_scores(dectree_kp, *tt_list_split_kirk_picard_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aa0c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pipeline(gs_bayes, tt_list_split_kirk_picard_5_words[0], tt_list_split_kirk_picard_5_words[1])\n",
    "bayes_kp = gs_bayes.best_estimator_\n",
    "bayes_kp_scores = get_scores(bayes_kp, *tt_list_split_kirk_picard_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cefae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pipeline(gs_forest, tt_list_split_kirk_picard_5_words[0], tt_list_split_kirk_picard_5_words[1])\n",
    "forest_kp = gs_forest.best_estimator_\n",
    "forest_kp_scores = get_scores(forest_kp, *tt_list_split_kirk_picard_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7bf4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pipeline(gs_logreg_tvec, tt_list_split_kirk_picard_5_words[0], tt_list_split_kirk_picard_5_words[1])\n",
    "logreg_tvec_kp = gs_logreg_tvec.best_estimator_\n",
    "logreg_tvec_kp_scores = get_scores(logreg_tvec_kp, *tt_list_split_kirk_picard_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcddc0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pipeline(gs_dectree_tvec, tt_list_split_kirk_picard_5_words[0], tt_list_split_kirk_picard_5_words[1])\n",
    "dectree_tvec_kp = gs_dectree_tvec.best_estimator_\n",
    "dectree_tvec_kp_scores = get_scores(dectree_tvec_kp, *tt_list_split_kirk_picard_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6f1fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pipeline(gs_bayes_tvec, tt_list_split_kirk_picard_5_words[0], tt_list_split_kirk_picard_5_words[1])\n",
    "bayes_tvec_kp = gs_bayes_tvec.best_estimator_\n",
    "bayes_tvec_kp_scores = get_scores(bayes_tvec_kp, *tt_list_split_kirk_picard_5_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84b6fb2",
   "metadata": {},
   "source": [
    "<a name=\"fit_basic_models_capt\"></a>\n",
    "#### Fit Basic Models (Vectorized Lines) for all captains\n",
    "- using the above Vectorizers (CountVectorizer and Tf-idf)\n",
    "- using the above models (LogisticRegression, DecisionTree, Multinomial Native Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b3b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pipeline(gs_logreg, tt_list_split_all_capt_5_words[0], tt_list_split_all_capt_5_words[1])\n",
    "logreg_allc = gs_logreg.best_estimator_\n",
    "logreg_allc_scores = get_scores(logreg_allc, *tt_list_split_all_capt_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b40911",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pipeline(gs_dectree, tt_list_split_all_capt_5_words[0], tt_list_split_all_capt_5_words[1])\n",
    "dectree_allc = gs_dectree.best_estimator_\n",
    "dectree_allc_scores = get_scores(dectree_allc, *tt_list_split_all_capt_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e481fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pipeline(gs_bayes_multi, tt_list_split_all_capt_5_words[0], tt_list_split_all_capt_5_words[1])\n",
    "bayes_allc = gs_bayes_multi.best_estimator_\n",
    "bayes_allc_scores = get_scores(bayes_allc, *tt_list_split_all_capt_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48416515",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pipeline(gs_forest, tt_list_split_all_capt_5_words[0], tt_list_split_all_capt_5_words[1])\n",
    "forest_allc = gs_forest.best_estimator_\n",
    "forest_allc_scores = get_scores(forest_allc, *tt_list_split_all_capt_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1c3da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pipeline(gs_logreg_tvec, tt_list_split_all_capt_5_words[0], tt_list_split_all_capt_5_words[1])\n",
    "logreg_tvec_allc = gs_logreg_tvec.best_estimator_\n",
    "logreg_tvec_allc_scores = get_scores(logreg_tvec_allc, *tt_list_split_all_capt_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab96e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pipeline(gs_dectree_tvec, tt_list_split_all_capt_5_words[0], tt_list_split_all_capt_5_words[1])\n",
    "dectree_tvec_allc = gs_dectree_tvec.best_estimator_\n",
    "dectree_tvec_allc_scores = get_scores(dectree_tvec_allc, *tt_list_split_all_capt_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pipeline(gs_bayes_tvec_multi, tt_list_split_all_capt_5_words[0], tt_list_split_all_capt_5_words[1])\n",
    "bayes_tvec_allc = gs_bayes_tvec_multi.best_estimator_\n",
    "bayes_tvec_allc_scores = get_scores(bayes_tvec_allc, *tt_list_split_all_capt_5_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347fb623",
   "metadata": {},
   "source": [
    "<a name=\"eval_basic_models\"></a>\n",
    "## Evaluating Basic Models\n",
    "\n",
    "In this section basic models will be evaluated with regards to their accuracy, ROC- and Precision-Recall Curves. \n",
    "\n",
    "**Section Overview**\n",
    "- [Evaluating Basic Models](#eval_basic_models)\n",
    "    - [Model evaluation functions](#eval_functions)\n",
    "    - [Kirk vs Picard](#kirkvpicard_eval)\n",
    "        - [Overview](#kirkvpicard_overview_eval)\n",
    "        - [Logistic Regression -  Kirk vs Picard](#kirkvpicard_logreg)\n",
    "        - [Decision Tree -  Kirk vs Picard](#kirkvpicard_dectree)\n",
    "        - [Bernoulli Native Bayes - Kirk vs Picard](#kirkvpicard_bayes)\n",
    "        - [Random Forest - Kirk vs Picard](#krikvpicard_random_forest)\n",
    "        - [Logistic Regression + tfidf - Kirk vs Picard](#krikvpicard_logreg_tfidf)\n",
    "        - [Decision Tree + tfidf - Kirk vs Picard](#krikvpicard_dectree_tfidf)\n",
    "        - [Bernoulli Naive Bayes + tfidf - Kirk vs Picard](#krikvpicard_bayes_tfidf)\n",
    "    - [All Captains](#allc_eval)\n",
    "        - [Overview](#allc_overview_eval)\n",
    "        - [Logistic Regression -  All Captains](#allc_logreg)\n",
    "        - [Decision Tree -   All Captains](#allc_dectree)\n",
    "        - [Bernoulli Native Bayes -  All Captains](#allc_bayes)\n",
    "        - [Random Forest -  All Captains](#allc_random_forest)\n",
    "        - [Logistic Regression + tfidf -  All Captains](#allc_logreg_tfidf)\n",
    "        - [Decision Tree + tfidf -  All Captains](#allc_dectree_tfidf)\n",
    "        - [Bernoulli Naive Bayes + tfidf -  All Captains](#allc_bayes_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35e4d29",
   "metadata": {},
   "source": [
    "<a name=\"eval_functions\"></a>\n",
    "#### Model evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d10657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logreg_coef_from_pipeline(pipeline, vectorizer_name, model_name, multiclass=False, \n",
    "                                  class_of_interest=None):\n",
    "    \"\"\"Gets coefficients from a model (that has a .coef_ attribute) within a fitted pipeline. \n",
    "    Returns a dataframe.\n",
    "    Arguments:\n",
    "        pipeline = fitted pipeline\n",
    "        vectorizer_name = name assigned to the vectorizer in the pipeline\n",
    "        model_name = name assigned to the model in the pipeline\n",
    "        multiclass = whether or not the classification is multiclass (default=False)\n",
    "        class_of_interest = in case of multiclass, for which class coefficients are wanted (default=None)\n",
    "                            should be specified as the class name (string).\"\"\"\n",
    "    array_classes = pipeline.named_steps[model_name].classes_\n",
    "    class_of_interest_index = np.where(array_classes == class_of_interest) #get the index of the class of interest\n",
    "    \n",
    "    # in case of multiclass get coefficients from the class of interest\n",
    "    if multiclass == True:\n",
    "        coefs = pipeline.named_steps[model_name].coef_[class_of_interest_index]\n",
    "    if multiclass == False:\n",
    "        coefs = pipeline.named_steps[model_name].coef_\n",
    "    \n",
    "    # get the name of the coefficients\n",
    "    vocab_unsorted = pipeline.named_steps[vectorizer_name].vocabulary_\n",
    "    vocab_sorted_by_index = sorted(vocab_unsorted.keys())\n",
    "    \n",
    "    # create the dataframe\n",
    "    df =  pd.DataFrame(coefs.reshape(-1,1),columns=['coef'], index= vocab_sorted_by_index)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_coef_dataframe(df, lenght=20, positive=True, ax=None):\n",
    "    \"\"\"Plots either the coefficients with the highest, or the lowest value, given a dataframe of coefficients.\n",
    "    Arguments:\n",
    "        df = dataframe of coefficients\n",
    "        positive = boolean value indicating whether to plot top or bottom coeffiecients (default=True)\n",
    "        ax = subplot position (default=None).\"\"\"\n",
    "    if positive == True:\n",
    "        return sns.barplot(y=df.sort_values(by=\"coef\", ascending=False).index[:lenght], \n",
    "                x=df.sort_values(by=\"coef\", ascending=False).coef[:lenght],\n",
    "                orient=\"h\",\n",
    "                ax=ax, edgecolor=\"black\",\n",
    "                color=\"#9A99FF\")\n",
    "    if positive == False:\n",
    "        return sns.barplot(y=df.sort_values(by=\"coef\", ascending=True).index[:lenght], \n",
    "                x=df.sort_values(by=\"coef\", ascending=True).coef.apply(lambda x: -x)[:lenght],\n",
    "                orient=\"h\",\n",
    "                ax=ax)     \n",
    "       \n",
    "    \n",
    "def plot_graphs_logreg_binary(df_coef, model, X_test, y_test, lenght=20, pos_label=\"1\", neg_label=\"0\", \n",
    "                              coef_plot=True):\n",
    "    \"\"\"Plots the following graphs for a binary classification: Coefficient for positive label, coefficients\n",
    "    for negative labels, confusion matrix, ROC-curve, Precision-Recall-Curve, barplot of baseline counts.\n",
    "    Arguments:\n",
    "        df_coef = dataframe of coefficients\n",
    "        model = fitted model\n",
    "        X_test = predictors test set\n",
    "        y_test = target test set\n",
    "        lenght = number of coefficients to plot (default=20)\n",
    "        pos_label = label of the positive class (default=\"1\")\n",
    "        neg_label = label of the negative class (default=\"0\")\n",
    "        coef_plot = turn the plotting of coefficients on/off (default=True)\"\"\"\n",
    "    \n",
    "    if coef_plot == True:\n",
    "    \n",
    "        fig, ax = plt.subplots(nrows=3, ncols=2, figsize=(20,20))\n",
    "\n",
    "        ax[2][0].set_title(f\"Coefficients predicting for {pos_label}\")\n",
    "        plot_coef_dataframe(df_coef, lenght, ax=ax[2][0])\n",
    "\n",
    "        ax[2][1].set_title(f\"Coefficients predicting for {neg_label}\")\n",
    "        plot_coef_dataframe(df_coef, lenght, positive=False, ax=ax[2][1])\n",
    "        \n",
    "    if coef_plot == False:\n",
    "        fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15,10))\n",
    "\n",
    "    plot_confusion_matrix(model, X_test, y_test, ax=ax[0][0], colorbar=False, cmap=\"Blues\")\n",
    "    plot_roc_curve(model, X_test, y_test, ax=ax[0][1])\n",
    "    plot_precision_recall_curve(model, X_test, y_test, ax=ax[1][0])\n",
    "\n",
    "    sns.barplot(x=y_test.value_counts().index, y=y_test.value_counts().values, ax=ax[1][1])\n",
    "    \n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_graphs_logreg_five_classes(pipeline, vectorizer_name, model_name, X_test, y_test, lenght=20, label=[]):\n",
    "    \"\"\"Plots the following graphs for a 5-class multiclass classification: Coefficients for each label, \n",
    "    confusion matrix, ROC-curve.\n",
    "    Arguments:\n",
    "        pipeline = fitted pipeline\n",
    "        vectorizer_name = name of the vectorizer within the pipeline\n",
    "        model_name = name of the model within the pipeline\n",
    "        X_test = predictors test set\n",
    "        y_test = target test set\n",
    "        lenght = number of coefficients to plot (default=20)\n",
    "        label = list of all labels (default=[])\"\"\"\n",
    "    \n",
    "    # getting coefficient dataframes\n",
    "    df1 = get_logreg_coef_from_pipeline(pipeline, vectorizer_name, \n",
    "                                       model_name, multiclass=True, class_of_interest=label[0].lower())\n",
    "    df2 = get_logreg_coef_from_pipeline(pipeline, vectorizer_name, \n",
    "                                       model_name, multiclass=True, class_of_interest=label[1].lower())\n",
    "    df3 = get_logreg_coef_from_pipeline(pipeline, vectorizer_name, \n",
    "                                       model_name, multiclass=True, class_of_interest=label[2].lower())\n",
    "    df4 = get_logreg_coef_from_pipeline(pipeline, vectorizer_name, \n",
    "                                       model_name, multiclass=True, class_of_interest=label[3].lower())\n",
    "    df5 = get_logreg_coef_from_pipeline(pipeline, vectorizer_name, \n",
    "                                       model_name, multiclass=True, class_of_interest=label[4].lower())\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=4, ncols=2, figsize=(20,50))\n",
    "\n",
    "    ax[0][0].set_title(f\"Coefficients predicting for {label[0]}\")\n",
    "    plot_coef_dataframe(df1, lenght, ax=ax[0][0])\n",
    "\n",
    "    ax[0][1].set_title(f\"Coefficients predicting for {label[1]}\")\n",
    "    plot_coef_dataframe(df2, lenght, ax=ax[0][1])\n",
    "\n",
    "    ax[1][0].set_title(f\"Coefficients predicting for {label[2]}\")\n",
    "    plot_coef_dataframe(df3, lenght, ax=ax[1][0])\n",
    "    \n",
    "    ax[1][1].set_title(f\"Coefficients predicting for {label[3]}\")\n",
    "    plot_coef_dataframe(df4, lenght, ax=ax[1][1])\n",
    "    \n",
    "    ax[2][0].set_title(f\"Coefficients predicting for {label[4]}\")\n",
    "    plot_coef_dataframe(df5, lenght, ax=ax[2][0])\n",
    "    \n",
    "    ax[0][0].set_xlabel(\"Coefficient\")\n",
    "    ax[0][1].set_xlabel(\"Coefficient\")\n",
    "    ax[1][0].set_xlabel(\"Coefficient\")\n",
    "    ax[0][1].set_xlabel(\"Coefficient\")\n",
    "    ax[2][0].set_xlabel(\"Coefficient\")\n",
    "    \n",
    "    strek_colors = ListedColormap([\"#C6F6FA\", \"#7CEAF4\", \"#2FDEEE\", \"#0FAEBD\", \"#0B7A84\"])\n",
    "\n",
    "    plt.rcParams.update({'font.size': 25})\n",
    "    \n",
    "    plot_confusion_matrix(pipeline, X_test, y_test, ax=ax[2][1], colorbar=True, cmap=strek_colors,\n",
    "                         display_labels=[\"Archer\", \"Janeway\", \"Kirk\", \"Picard\", \"Sisko\"],\n",
    "                         values_format=\"d\")\n",
    "    \n",
    "    ax[2][1].tick_params(labelsize=25)\n",
    "    ax[2][1].grid(False)\n",
    "    \n",
    "    skplt.metrics.plot_roc(y_test, pipeline.predict_proba(X_test), \n",
    "                       plot_micro=True, plot_macro=True, \n",
    "                       title_fontsize=20, text_fontsize=16, figsize=(8,6), ax=ax[3][0])\n",
    "    \n",
    "    ax[-1, -1].axis('off')\n",
    "    \n",
    "    ax[3][0].legend(loc=(1,0))\n",
    "    fig.subplots_adjust(hspace=0.4)\n",
    "    fig.subplots_adjust(wspace=0.5)\n",
    "    \n",
    "    sns.despine()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4997db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fea_importances_from_pipeline(pipeline, vectorizer_name, model_name, multiclass=False, \n",
    "                                      class_of_interest=None):\n",
    "    \"\"\"Gets feature importances from a fitted pipeline that includes a model with a .feature_importances_ method\n",
    "    and returns a dataframe.\n",
    "    Arguments:\n",
    "        pipeline = fitted pipeline\n",
    "        vectorizer_name = name assigned to the vectorizer in the pipeline\n",
    "        model_name = name assigned to the model in the pipeline\n",
    "        multiclass = whether or not the classification is multiclass (default=False)\n",
    "        class_of_interest = in case of multiclass, for which class coefficients are wanted (default=None)\n",
    "                            should be specified as the class name (string).\"\"\"\n",
    "    \n",
    "    array_classes = pipeline.named_steps[model_name].classes_\n",
    "    class_of_interest_index = np.where(array_classes == class_of_interest)\n",
    "    \n",
    "    if multiclass == True:\n",
    "        fea_importances = pipeline.named_steps[model_name].feature_importances_[class_of_interest_index]\n",
    "    if multiclass == False:\n",
    "        fea_importances = pipeline.named_steps[model_name].feature_importances_\n",
    "    \n",
    "    vocab_unsorted = pipeline.named_steps[vectorizer_name].vocabulary_\n",
    "    vocab_sorted_by_index = sorted(vocab_unsorted.keys())\n",
    "    \n",
    "    df =  pd.DataFrame(fea_importances.reshape(-1,1),columns=['feature_importance'], index= vocab_sorted_by_index)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_fea_importance_dataframe(df, lenght=20, positive=True, ax=None):\n",
    "    \"\"\"Plots either the coefficients with the highest, or the lowest value, given a dataframe of coefficients.\n",
    "    Arguments:\n",
    "        df = dataframe of coefficients\n",
    "        lenght = number of coefficients to plot (default = 20)\n",
    "        positive = boolean value indicating whether to plot top or bottom coeffiecients (default=True)\n",
    "        ax = subplot position (default=None).\"\"\"\n",
    "    if positive == True:\n",
    "        return sns.barplot(y=df.sort_values(by=\"feature_importance\", ascending=False).index[:lenght], \n",
    "                x=df.sort_values(by=\"feature_importance\", ascending=False).feature_importance[:lenght],\n",
    "                orient=\"h\",\n",
    "                ax=ax, color=\"#CC6698\")\n",
    "    if positive == False:\n",
    "        return sns.barplot(y=df.sort_values(by=\"feature_importance\", ascending=True).index[:lenght], \n",
    "                x=df.sort_values(by=\"feature_importance\", ascending=True).feature_importance.apply(lambda x: -x)[:lenght],\n",
    "                orient=\"h\",\n",
    "                ax=ax) \n",
    "\n",
    "def plot_graphs_dectree_binary(df_fea, model, X_test, y_test, lenght=20, pos_label=\"1\", neg_label=\"0\"):\n",
    "    \"\"\"Plots the following graphs for a binary classification: Feature importances,\n",
    "    confusion matrix, ROC-curve, Precision-Recall-Curve, barplot of baseline counts.\n",
    "    Arguments:\n",
    "        df_fea = dataframe of feature importances\n",
    "        model = fitted model\n",
    "        X_test = predictors test set\n",
    "        y_test = target test set\n",
    "        lenght = number of feature importances to plot (default=20)\n",
    "        pos_label = label of the positive class (default=\"1\")\n",
    "        neg_label = label of the negative class (default=\"0\")\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15,15))\n",
    "\n",
    "    ax[0][0].set_title(f\"Feature importances\")\n",
    "    plot_fea_importance_dataframe(df_fea, lenght, ax=ax[0][0])\n",
    "\n",
    "    plot_confusion_matrix(model, X_test, y_test, ax=ax[0][1], colorbar=False, cmap=\"Blues\")\n",
    "    plot_roc_curve(model, X_test, y_test, ax=ax[1][0])\n",
    "    plot_precision_recall_curve(model, X_test, y_test, ax=ax[1][1])\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_graphs_DecTree_five_classes(pipeline, vectorizer_name, model_name, X_test, y_test, lenght=20, label=[]):\n",
    "    \"\"\"Plots the following graphs for a 5-class multiclass classification: Feature importances, \n",
    "    confusion matrix, ROC-curve.\n",
    "    Arguments:\n",
    "        pipeline = fitted pipeline\n",
    "        vectorizer_name = name of the vectorizer within the pipeline\n",
    "        model_name = name of the model within the pipeline\n",
    "        X_test = predictors test set\n",
    "        y_test = target test set\n",
    "        lenght = number of coefficients to plot (default=20)\n",
    "        label = list of all labels (default=[])\"\"\"\n",
    "    \n",
    "    df1 = get_fea_importances_from_pipeline(pipeline, vectorizer_name, model_name)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15,10))\n",
    "\n",
    "    ax[0][0].set_title(f\"Feature importances\")\n",
    "    \n",
    "    plot_fea_importance_dataframe(df1, lenght, ax=ax[0][0])\n",
    "    \n",
    "    strek_colors = ListedColormap([\"#C6F6FA\", \"#7CEAF4\", \"#2FDEEE\", \"#0FAEBD\", \"#0B7A84\"])\n",
    "\n",
    "    plot_confusion_matrix(pipeline, X_test, y_test, ax=ax[0][1], colorbar=False, cmap=strek_colors, \n",
    "                          display_labels=[\"Archer\", \"Janeway\", \"Kirk\", \"Picard\", \"Sisko\"])\n",
    "    \n",
    "    skplt.metrics.plot_roc(y_test, pipeline.predict_proba(X_test), \n",
    "                       plot_micro=True, plot_macro=True, \n",
    "                       title_fontsize=20, text_fontsize=16, figsize=(8,6), ax=ax[1][0])\n",
    "    \n",
    "    ax[-1, -1].axis('off')\n",
    "    \n",
    "    ax[1][0].legend(loc=(1,0))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_decision_tree_graph(pipeline, vectorizer_name, model_name):\n",
    "    \"\"\"Plots the graph of a decision tree.\n",
    "    Arguments:\n",
    "        pipeline = fitted pipeline\n",
    "        vectorizer_name = name of the vectorizer within the pipeline\n",
    "        model_name = name of the model within the pipeline.\"\"\"\n",
    "    dot_data = export_graphviz(pipeline.named_steps[model_name],\n",
    "                filled=True,\n",
    "                rounded=True,\n",
    "                special_characters=False,\n",
    "                feature_names= sorted(pipeline.named_steps[vectorizer_name].vocabulary_.keys())\n",
    "                )\n",
    "\n",
    "    graph = graphviz.Source(dot_data) \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed61b38",
   "metadata": {},
   "source": [
    "<a name=kirkvpicard_eval></a>\n",
    "### Kirk vs Picard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc84b688",
   "metadata": {},
   "source": [
    "<a name=\"kirkvpicard_overview_eval\"></a>\n",
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kp_scores = pd.DataFrame([[*logreg_kp_scores], [*dectree_kp_scores], [*bayes_kp_scores], [*forest_kp_scores], \n",
    "               [*logreg_tvec_kp_scores], [*dectree_tvec_kp_scores], [*bayes_tvec_kp_scores]], \n",
    "               index=[\"LogReg + Cvec\", \"Decision Tree + Cvec\", \"Bernoulli naive bayes + Cvec\", \n",
    "                      \"Random Forest + Cvec\", \"LogReg + tfidf\", \"Decision Tree + tfidf\",\n",
    "                      \"Bernoulli naive bayes + tfidf\"],\n",
    "                columns=[\"Training Score\", \"Mean Cross-Val Score\", \"Test Score\"]).sort_values(by=\"Mean Cross-Val Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1875f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "bar_chart = ax.barh(df_kp_scores.index, df_kp_scores[\"Mean Cross-Val Score\"], color=\"teal\")\n",
    "\n",
    "for bar, score in zip(ax.patches, df_kp_scores[\"Mean Cross-Val Score\"]):\n",
    "    ax.text(bar.get_x()+bar.get_width()+0.01, bar.get_y()+bar.get_height()/2,round(score,3), \n",
    "            color = 'black', ha = 'left', va = 'center', size=14)\n",
    "\n",
    "ax.set_title(\"Mean CV Scores by model (Kirk vs. Picard)\")\n",
    "plt.xlim(0,0.75);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fe01dc",
   "metadata": {},
   "source": [
    "<a name=kirkvpicard_logreg></a>\n",
    "#### Logistic Regression -  Kirk vs Picard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f7ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef = get_logreg_coef_from_pipeline(logreg_kp_5w, \"vect\", \"logreg\")\n",
    "plot_graphs_logreg_binary(df_coef, logreg_kp, tt_list_split_kirk_picard_5_words[2], \n",
    "                   tt_list_split_kirk_picard_5_words[3], pos_label=\"picard\", neg_label=\"kirk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c26250e",
   "metadata": {},
   "source": [
    "<a name=kirkvpicard_dectree></a>\n",
    "#### Decision Tree -  Kirk vs Picard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059bdc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fea = get_fea_importances_from_pipeline(dectree_kp_5w, \"vect\", \"DecTree\")\n",
    "\n",
    "plot_graphs_dectree_binary(df_fea, dectree_kp_5w, tt_list_split_kirk_picard_5_words[2], \n",
    "                   tt_list_split_kirk_picard_5_words[3], pos_label=\"picard\", neg_label=\"kirk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc7138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_tree_graph(dectree_kp_5w, \"vect\", \"DecTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed01c0a",
   "metadata": {},
   "source": [
    "<a name=kirkvpicard_bayes></a>\n",
    "#### Bernoulli Naive Bayes - Kirk vs Picard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c561b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = bayes_kp_5w.named_steps[\"BernoulliNB\"].coef_\n",
    "\n",
    "vocab_unsorted = bayes_kp_5w.named_steps[\"vect\"].vocabulary_\n",
    "vocab_sorted_by_index = sorted(vocab_unsorted.keys())\n",
    "\n",
    "df =  pd.DataFrame(coefs.reshape(-1,1),columns=['coef'], index= vocab_sorted_by_index)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.barh(df.sort_values(\"coef\", ascending=False).head(20).index, df.sort_values(\"coef\", ascending=False).head(20).coef);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32f6f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef = get_logreg_coef_from_pipeline(bayes_kp_5w, \"vect\", \"BernoulliNB\")\n",
    "plot_graphs_logreg_binary(df_coef, bayes_kp_5w, tt_list_split_kirk_picard_5_words[2], \n",
    "                   tt_list_split_kirk_picard_5_words[3], pos_label=\"picard\", neg_label=\"kirk\", coef_plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f1cddb",
   "metadata": {},
   "source": [
    "<a name=\"krikvpicard_random_forest\"></a>\n",
    "#### Random Forest - Kirk vs Picard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c532f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fea = get_fea_importances_from_pipeline(forest_kp, \"vect\", \"Forest\")\n",
    "\n",
    "plot_graphs_dectree_binary(df_fea,forest_kp, tt_list_split_kirk_picard_5_words[2], \n",
    "                   tt_list_split_kirk_picard_5_words[3], pos_label=\"picard\", neg_label=\"kirk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce27ee0",
   "metadata": {},
   "source": [
    "<a name=\"krikvpicard_logreg_tfidf\"></a>\n",
    "#### Logistic Regression + tfidf - Kirk vs Picard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17b3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef = get_logreg_coef_from_pipeline(logreg_tvec_kp, \"vect\", \"logreg\")\n",
    "plot_graphs_logreg_binary(df_coef, logreg_tvec_kp, tt_list_split_kirk_picard_5_words[2], \n",
    "                   tt_list_split_kirk_picard_5_words[3], pos_label=\"picard\", neg_label=\"kirk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47cc0a9",
   "metadata": {},
   "source": [
    "<a name=\"krikvpicard_dectree_tfidf\"></a>\n",
    "#### Decision Tree + tfidf - Kirk vs Picard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1278bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fea = get_fea_importances_from_pipeline(dectree_tvec_kp, \"vect\", \"DecTree\")\n",
    "\n",
    "plot_graphs_dectree_binary(df_fea, dectree_tvec_kp, tt_list_split_kirk_picard_5_words[2], \n",
    "                   tt_list_split_kirk_picard_5_words[3], pos_label=\"picard\", neg_label=\"kirk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5be9c4a",
   "metadata": {},
   "source": [
    "<a name=\"krikvpicard_bayes_tfidf\"></a>\n",
    "#### Bernoulli Naive Bayes + tfidf - Kirk vs Picard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb96d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = bayes_tvec_kp.named_steps[\"BernoulliNB\"].coef_\n",
    "\n",
    "vocab_unsorted = bayes_tvec_kp.named_steps[\"vect\"].vocabulary_\n",
    "vocab_sorted_by_index = sorted(vocab_unsorted.keys())\n",
    "\n",
    "df =  pd.DataFrame(coefs.reshape(-1,1),columns=['coef'], index= vocab_sorted_by_index)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.barh(df.sort_values(\"coef\", ascending=False).head(20).index, df.sort_values(\"coef\", ascending=False).head(20).coef);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067a478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef = get_logreg_coef_from_pipeline(bayes_tvec_kp, \"vect\", \"BernoulliNB\")\n",
    "plot_graphs_logreg_binary(df_coef, bayes_tvec_kp, tt_list_split_kirk_picard_5_words[2], \n",
    "                   tt_list_split_kirk_picard_5_words[3], pos_label=\"picard\", neg_label=\"kirk\", coef_plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9720adab",
   "metadata": {},
   "source": [
    "<a name=allc_eval></a>\n",
    "### All Captains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83fd8a",
   "metadata": {},
   "source": [
    "<a name=\"allc_overview_eval\"></a>\n",
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324b640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create overview dataframe all basic models\n",
    "df_allc_scores = pd.DataFrame([[*logreg_allc_scores], [*dectree_allc_scores], [*bayes_allc_scores], \n",
    "                             [*forest_allc_scores], [*logreg_tvec_allc_scores], [*dectree_tvec_allc_scores], \n",
    "                             [*bayes_tvec_allc_scores]], \n",
    "                       index=[\"Logistic Regression + Cvec\", \"Decision Tree + Cvec\", \"Bernoulli Naive Bayes + Cvec\", \n",
    "                      \"Random Forest + Cvec\", \"Logistic Regression + Tfidf\", \"Decision Tree + Tfidf\",\n",
    "                      \"Bernoulli naive bayes + Tfidf\"],\n",
    "                       columns=[\"Training Score\", \"Mean Cross-Val Score\", \"Test Score\"]).sort_values(\"Mean Cross-Val Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3158e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean test score all basic models\n",
    "np.mean(df_allc_scores[\"Test Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13f8545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot overview test accuracy all models\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "# create bar chart\n",
    "bar_chart = ax.barh(df_allc_scores.index, df_allc_scores[\"Test Score\"], \n",
    "                    color=[\"#FFCC9A\",\"#FFCC9A\",\"#FFCC9A\",\"#1671A2\",\"#1671A2\",\"#1671A2\",\"#1671A2\"], \n",
    "                    edgecolor=\"black\")\n",
    "\n",
    "# add test score to the bar charts\n",
    "for bar, score in zip(ax.patches, df_allc_scores[\"Test Score\"]):\n",
    "    if score > np.mean(df_allc_scores[\"Test Score\"]): # add score to the right if > mean\n",
    "        ax.text(bar.get_x()+bar.get_width()+0.01, bar.get_y()+bar.get_height()/2,round(score,3), \n",
    "            color = 'black', ha = 'left', va = 'center', size=20)\n",
    "    else: # add score within bar if < mean\n",
    "        ax.text(bar.get_x()+bar.get_width()-0.05, bar.get_y()+bar.get_height()/2,round(score,3), \n",
    "            color = 'black', ha = 'left', va = 'center', size=20)        \n",
    "\n",
    "# add title\n",
    "ax.set_title(\"Test Accuracy Scores\", size=25)\n",
    "\n",
    "# change ticksize\n",
    "plt.xticks(size=20)\n",
    "plt.yticks(size=20)\n",
    "\n",
    "# add axline at baseline accuracy\n",
    "plt.axvline(round(0.250000,2), **{\"c\":\"black\"})\n",
    " \n",
    "# add baseline text\n",
    "ax.text(0.23,-1.5, \"Baseline\", fontproperties={\"size\":20, \"style\":\"italic\"})\n",
    "\n",
    "# customize length x-axis\n",
    "plt.xlim(0,0.45);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d8699",
   "metadata": {},
   "source": [
    "<a name=allc_logreg></a>\n",
    "#### Logistic Regression -  All Captains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fabc5f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_graphs_logreg_five_classes(logreg_tvec_allc, \"vect\", \"logreg\", tt_list_split_all_capt_5_words[2], \n",
    "                   tt_list_split_all_capt_5_words[3], label=[\"Archer\", \"Kirk\", \"Picard\", \"Sisko\", \"Janeway\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc15f251",
   "metadata": {},
   "source": [
    "<a name=allc_dectree></a>\n",
    "#### Decision Tree -  All Captains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a7d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs_DecTree_five_classes(dectree_allc, \"vect\", \"DecTree\", tt_list_split_all_capt_5_words[2], \n",
    "                   tt_list_split_all_capt_5_words[3], label=[\"archer\", \"kirk\", \"picard\", \"sisko\", \"janeway\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67eb6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_tree_graph(dectree_allc, \"vect\", \"DecTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b724c7",
   "metadata": {},
   "source": [
    "<a name=allc_bayes></a>\n",
    "#### Bernoulli Naive Bayes - All Captains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baef8b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs_logreg_five_classes(bayes_allc, \"vect\", \"MultinomialNB\", tt_list_split_all_capt_5_words[2], \n",
    "                   tt_list_split_all_capt_5_words[3], label=[\"archer\", \"kirk\", \"picard\", \"sisko\", \"janeway\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fca469",
   "metadata": {},
   "source": [
    "<a name=\"allc_random_forest\"></a>\n",
    "#### Random Forest - All Captains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d06da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs_DecTree_five_classes(forest_allc, \"vect\", \"Forest\", tt_list_split_all_capt_5_words[2], \n",
    "                   tt_list_split_all_capt_5_words[3], label=[\"archer\", \"kirk\", \"picard\", \"sisko\", \"janeway\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ab10f0",
   "metadata": {},
   "source": [
    "<a name=\"allc_logreg_tfidf\"></a>\n",
    "#### Logistic Regression + tfidf - All Captains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9218a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs_logreg_five_classes(logreg_tvec_allc, \"vect\", \"logreg\", tt_list_split_all_capt_5_words[2], \n",
    "                   tt_list_split_all_capt_5_words[3], label=[\"archer\", \"kirk\", \"picard\", \"sisko\", \"janeway\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053e3539",
   "metadata": {},
   "source": [
    "<a name=allc_dectree_tfidf></a>\n",
    "#### Decision Tree + tfidf -  All Captains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47511de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs_DecTree_five_classes(dectree_tvec_allc, \"vect\", \"DecTree\", tt_list_split_all_capt_5_words[2], \n",
    "                   tt_list_split_all_capt_5_words[3], label=[\"archer\", \"kirk\", \"picard\", \"sisko\", \"janeway\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa073d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_tree_graph(dectree_tvec_allc, \"vect\", \"DecTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebbcce6",
   "metadata": {},
   "source": [
    "<a name=allc_bayes_tfidf></a>\n",
    "#### Bernoulli Naive Bayes + tfidf- All Captains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af03d16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs_logreg_five_classes(bayes_tvec_allc, \"vect\", \"MultinomialNB\", tt_list_split_all_capt_5_words[2], \n",
    "                   tt_list_split_all_capt_5_words[3], label=[\"archer\", \"kirk\", \"picard\", \"sisko\", \"janeway\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9972ef",
   "metadata": {},
   "source": [
    "# Models with Additional Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53942ca",
   "metadata": {},
   "source": [
    "<a name=\"import_glove\"></a>\n",
    "#### Importing GloVe Embeddings\n",
    "\n",
    "Using pre-trained embeddings from <a href=\"https://github.com/stanfordnlp/GloVe\">GloVe</a> (Wikipedia crawl). I will use the 300 dimensional set for modelling and the 50 dimensional set for finding the average word of a character. The reason to use less dimensions when looking for closest embedding is that the higher dimensional set overfits and highly specific words (or combinations of letters and numbers) are returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8263350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "\n",
    "with open(\"/Users/tjanif/Desktop/KirkvPicard_Material/embeddings/glove.6B.300d.txt\") as file:\n",
    "    for line in file:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60184956",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_embeddings_dict = {}\n",
    "\n",
    "with open(\"/Users/tjanif/Desktop/KirkvPicard_Material/embeddings/glove.6B.50d.txt\") as file:\n",
    "    for line in file:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        few_embeddings_dict[word] = vector   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cc630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 300 vectors per word\n",
    "len(embeddings_dict[\"the\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af27f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 vectors per word \n",
    "len(few_embeddings_dict[\"the\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb76b07f",
   "metadata": {},
   "source": [
    "<a name=\"create_glove_functions\"></a>\n",
    "#### GloVe feature engineering functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaccc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count vectorizer for word-embeddings\n",
    "cvec_em = CountVectorizer(stop_words = \"english\",     \n",
    "                       ngram_range =(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b3492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lines_to_average_embedding_vect(arr_lines):\n",
    "    \"\"\"Takes in lines of dialog and calculates the average word embedding vector for the line, stopdwords\n",
    "    are excluded.\n",
    "    Arguments:\n",
    "        arr_lines = array of lines.\"\"\"\n",
    "    \n",
    "    # use CountVectorizer to create sparse matrix\n",
    "    sparse_matrix = cvec_em.fit_transform(arr_lines)\n",
    "\n",
    "    # dataframe of word counts, excluding common eclish words\n",
    "    df_em = pd.DataFrame(sparse_matrix.toarray(),columns=cvec_em.get_feature_names())\n",
    "    \n",
    "    line_vectors = []\n",
    "    \n",
    "    # iterating over lines\n",
    "    for line in df_em.index:\n",
    "        base_vectors = np.zeros(300)  #creating an empty (all 0) 300-dimensinal base vector\n",
    "        number_of_vectors = 0\n",
    "        \n",
    "        # iterating over all words in the set of lines\n",
    "        for word, entry in zip(df_em.columns, df_em.loc[line,:]):\n",
    "            \n",
    "            # in case the entry is not 0 (= the word occurs in the line)\n",
    "            if entry != 0:\n",
    "                try:\n",
    "                    word_vectors = embeddings_dict[word]  # get the word vector\n",
    "                    number_of_vectors += 1 \n",
    "                    base_vectors += word_vectors  #add the new vector to the vector for the whole line\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "        if number_of_vectors > 0:\n",
    "            base_vectors = base_vectors / number_of_vectors  # divide by number_of_vectors to get the average\n",
    "        line_vectors.append(base_vectors)\n",
    "    \n",
    "    return line_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0735a2f6",
   "metadata": {},
   "source": [
    "<a name=\"find_avg_word\"></a>\n",
    "#### Find the average word\n",
    "\n",
    "This is purely for fun. Using word embeddings one can calculate the average for all words in a text. With the `find_closest_embeddings` function the word closest to that average vector can be found. \n",
    "\n",
    "Interestingly the closest word to the average of each captain is the same: \"supposed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47faec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_average_word(arr_lines):\n",
    "    \"\"\"Function that averages all embedding vectors of a corpus of text\n",
    "    Arguments:\n",
    "        arr_lines = array of lines.\"\"\"\n",
    "    \n",
    "    # use CountVectorizer to create sparse matrix\n",
    "    sparse_matrix = cvec_em.fit_transform(arr_lines)\n",
    "\n",
    "    df_em = pd.DataFrame(sparse_matrix.toarray(),columns=cvec_em.get_feature_names())\n",
    "    \n",
    "\n",
    "    base_vectors = np.zeros(50)\n",
    "    number_of_vectors = 0\n",
    "    \n",
    "    for line in df_em.index:\n",
    "        for word, entry in zip(df_em.columns, df_em.loc[line,:]):\n",
    "            \n",
    "            if entry != 0:\n",
    "                try:\n",
    "                    word_vectors = few_embeddings_dict[word]\n",
    "                    number_of_vectors += 1\n",
    "                    base_vectors += word_vectors\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "\n",
    "    character_vector = base_vectors / number_of_vectors\n",
    "    print(number_of_vectors)\n",
    "    \n",
    "    return character_vector\n",
    "\n",
    "\n",
    "def find_closest_embeddings(embedding):\n",
    "    \"\"\"Function to find the word that matches a given embedding vector most closely.\n",
    "    Make sure the embedding dictionary used and the embedding given have the same dimensions!\n",
    "    Argument:\n",
    "        embedding = embedding vector\"\"\"\n",
    "    return sorted(few_embeddings_dict.keys(), \n",
    "                  key=lambda word: spatial.distance.euclidean(few_embeddings_dict[word], embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd8909",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_embeddings(find_the_average_word(lines_kirk))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce4c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_embeddings(find_the_average_word(lines_picard))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_embeddings(find_the_average_word(lines_sisko))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fd6de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_embeddings(find_the_average_word(lines_janeway))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e55101",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_embeddings(find_the_average_word(lines_archer))[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db4b4a",
   "metadata": {},
   "source": [
    "<a name=\"create_glove_features\"></a>\n",
    "### Create Features from GloVe Embeddings\n",
    "\n",
    "Using the average embedding vector per line said a new set of 300 features can be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958e2a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_em_kp = convert_lines_to_average_embedding_vect(df_lines_kirk_picard_pos.line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8dc29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_em_allc = convert_lines_to_average_embedding_vect(df_lines_all_captains_pos.line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a24768",
   "metadata": {},
   "source": [
    "<a name=\"combine_adv_features\"></a>\n",
    "### Combine Additional Features\n",
    "\n",
    "Putting GloVe Embeddings, grammatical features and number of words in a line into the same dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b3c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kp_adv_fea = pd.concat([df_lines_kirk_picard_pos.loc[:,\"character\":], \n",
    "                           pd.DataFrame(df_em_kp, index=df_lines_kirk_picard_pos.index)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9ef78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allc_adv_fea = pd.concat([df_lines_all_captains_pos.loc[:,\"character\":], \n",
    "                           pd.DataFrame(df_em_allc, index=df_lines_all_captains_pos.index)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d038667",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allc_adv_fea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5835a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kp_adv_fea.fillna(0, inplace=True)\n",
    "df_allc_adv_fea.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fafa07c",
   "metadata": {},
   "source": [
    "<a name=\"tts_advanced\"></a>\n",
    "#### Train-Test Split for Dataframes with Additional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dac29e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_tts_adv_fea(X,y,test_size=0.2, random_state=23):\n",
    "    \"\"\"Function to make a train test split in order X_train, y_train, X_test, y_test\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_size, random_state=random_state)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ded5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_list_split_adv_fea_kp = creating_tts_adv_fea(df_kp_adv_fea.loc[:,\"num_words\":], df_kp_adv_fea[\"character\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694b52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_list_split_adv_fea_kp[0].shape, tt_list_split_adv_fea_kp[1].shape, tt_list_split_adv_fea_kp[2].shape, tt_list_split_adv_fea_kp[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638bf9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_list_split_adv_fea_allc = creating_tts_adv_fea(df_allc_adv_fea.loc[:,\"num_words\":], \n",
    "                                                  df_allc_adv_fea[\"character\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1052dee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_list_split_adv_fea_allc[0].shape, tt_list_split_adv_fea_allc[1].shape, tt_list_split_adv_fea_allc[2].shape, tt_list_split_adv_fea_allc[3].shape, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59156e2b",
   "metadata": {},
   "source": [
    "<a name=\"scaling_adv\"></a>\n",
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a2276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate two scalers\n",
    "scaler_kp = StandardScaler()\n",
    "scaler_allc = StandardScaler()\n",
    "\n",
    "# kirk vs picard\n",
    "X_train_scaled_kp = pd.DataFrame(scaler_kp.fit_transform(tt_list_split_adv_fea_kp[0]),  # fit on train\n",
    "                                 columns=tt_list_split_adv_fea_kp[0].columns)\n",
    "X_test_scaled_kp = pd.DataFrame(scaler_kp.transform(tt_list_split_adv_fea_kp[2]), # transform test\n",
    "                                columns=tt_list_split_adv_fea_kp[2].columns)\n",
    "\n",
    "# all captains\n",
    "X_train_scaled_allc = pd.DataFrame(scaler_allc.fit_transform(tt_list_split_adv_fea_allc[0]), \n",
    "                                 columns=tt_list_split_adv_fea_allc[0].columns)\n",
    "X_test_scaled_allc = pd.DataFrame(scaler_allc.transform(tt_list_split_adv_fea_allc[2]), \n",
    "                                 columns=tt_list_split_adv_fea_allc[2].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18409e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictors - target lists in correct order\n",
    "tt_list_split_adv_fea_kp = [X_train_scaled_kp, tt_list_split_adv_fea_kp[1],\n",
    "                           X_test_scaled_kp, tt_list_split_adv_fea_kp[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c92387",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_list_split_adv_fea_allc = [X_train_scaled_allc, tt_list_split_adv_fea_allc[1],\n",
    "                           X_test_scaled_allc, tt_list_split_adv_fea_allc[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc77f3b",
   "metadata": {},
   "source": [
    "<a name=\"create_model_adv_fea\"></a>\n",
    "### Create a Model only using the Additional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8918b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "param_grid_logreg = {\n",
    "                \"penalty\" : [\"l1\", \"l2\"],\n",
    "                \"C\": np.logspace(-1, 4, 20)}\n",
    "\n",
    "gs_logreg_em = GridSearchCV(LogisticRegression(max_iter=50000), param_grid_logreg, n_jobs=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47b39a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression, faster version (less iterations)\n",
    "param_grid_logreg = {\"solver\":[\"saga\"],\n",
    "                \"penalty\" : [\"elasticnet\"],\n",
    "                \"l1_ratio\" : np.linspace(0,1,10),\n",
    "                \"C\": np.logspace(-2, 3, 20)}\n",
    "\n",
    "gs_logreg_em_fast = GridSearchCV(LogisticRegression(max_iter=1000), param_grid_logreg, n_jobs=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2364bd82",
   "metadata": {},
   "source": [
    "<a name=\"fit_model_only_adv_fea\"></a>\n",
    "### Fitting a Logistic Regression on only Additional Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150cfb14",
   "metadata": {},
   "source": [
    "#### Models Kirk vs Picard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9882d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pipeline(gs_logreg_em, tt_list_split_adv_fea_kp[0], tt_list_split_adv_fea_kp[1])\n",
    "logreg_adv_fea_kp = gs_logreg_em.best_estimator_\n",
    "logreg_adv_fea_kp_scores = get_scores(logreg_adv_fea_kp, *tt_list_split_adv_fea_kp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a46708",
   "metadata": {},
   "source": [
    "#### Models All Captains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77589b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pipeline(gs_logreg_em, tt_list_split_adv_fea_allc[0], tt_list_split_adv_fea_allc[1])\n",
    "logreg_adv_fea_allc = gs_logreg_em.best_estimator_\n",
    "logreg_adv_fea_allc_scores = get_scores(logreg_adv_fea_allc, *tt_list_split_adv_fea_allc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3592eea3",
   "metadata": {},
   "source": [
    "<a name=\"eval_models_only_adv_fea\"></a>\n",
    "### Evaluating Logistic Regression with only Additional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49e94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef = pd.DataFrame(logreg_adv_fea_kp.coef_.reshape(-1,1), index = tt_list_split_adv_fea_kp[0].columns,\n",
    "                       columns=[\"coef\"]).sort_values(by=\"coef\",ascending=False)\n",
    "plot_graphs_logreg_binary(df_coef, logreg_adv_fea_kp, tt_list_split_adv_fea_kp[2], \n",
    "                   tt_list_split_adv_fea_kp[3], pos_label=\"picard\", neg_label=\"kirk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454d3d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plots for all captains\n",
    "\n",
    "# get class labels\n",
    "label = logreg_adv_fea_allc.classes_\n",
    "\n",
    "# create coefficient dataframes\n",
    "df_coef_1 = pd.DataFrame(logreg_adv_fea_allc.coef_[0].reshape(-1,1), index = tt_list_split_adv_fea_allc[0].columns,\n",
    "                       columns=[\"coef\"]).sort_values(by=\"coef\",ascending=False)\n",
    "df_coef_2 = pd.DataFrame(logreg_adv_fea_allc.coef_[1].reshape(-1,1), index = tt_list_split_adv_fea_allc[0].columns,\n",
    "                       columns=[\"coef\"]).sort_values(by=\"coef\",ascending=False)\n",
    "df_coef_3 = pd.DataFrame(logreg_adv_fea_allc.coef_[2].reshape(-1,1), index = tt_list_split_adv_fea_allc[0].columns,\n",
    "                       columns=[\"coef\"]).sort_values(by=\"coef\",ascending=False)\n",
    "df_coef_4 = pd.DataFrame(logreg_adv_fea_allc.coef_[3].reshape(-1,1), index = tt_list_split_adv_fea_allc[0].columns,\n",
    "                       columns=[\"coef\"]).sort_values(by=\"coef\",ascending=False)\n",
    "df_coef_5 = pd.DataFrame(logreg_adv_fea_allc.coef_[4].reshape(-1,1), index = tt_list_split_adv_fea_allc[0].columns,\n",
    "                       columns=[\"coef\"]).sort_values(by=\"coef\",ascending=False)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, ncols=2, figsize=(20,30))\n",
    "\n",
    "# plot coefficients for each captain\n",
    "ax[0][0].set_title(f\"Coefficients predicting for {label[0]}\", size=20)\n",
    "plot_coef_dataframe(df_coef_1, 20, ax=ax[0][0])\n",
    "\n",
    "ax[0][1].set_title(f\"Coefficients predicting for {label[1]}\", size=20)\n",
    "plot_coef_dataframe(df_coef_2, 20, ax=ax[0][1])\n",
    "\n",
    "ax[1][0].set_title(f\"Coefficients predicting for {label[2]}\", size=20)\n",
    "plot_coef_dataframe(df_coef_3, 20, ax=ax[1][0])\n",
    "\n",
    "ax[1][1].set_title(f\"Coefficients predicting for {label[3]}\", size=20)\n",
    "plot_coef_dataframe(df_coef_4, 20, ax=ax[1][1])\n",
    "\n",
    "ax[2][0].set_title(f\"Coefficients predicting for {label[4]}\", size=20)\n",
    "plot_coef_dataframe(df_coef_5, 20, ax=ax[2][0])\n",
    "\n",
    "# confusion matix\n",
    "plot_confusion_matrix(logreg_adv_fea_allc, tt_list_split_adv_fea_allc[2], tt_list_split_adv_fea_allc[3], \n",
    "                      ax=ax[2][1], colorbar=False, cmap=\"Blues\")\n",
    "\n",
    "# ROC\n",
    "skplt.metrics.plot_roc(tt_list_split_adv_fea_allc[3], logreg_adv_fea_allc.predict_proba(tt_list_split_adv_fea_allc[2]), \n",
    "                    plot_micro=True, plot_macro=True, \n",
    "                    title_fontsize=20, text_fontsize=16, figsize=(8,6), ax=ax[3][0])\n",
    "\n",
    "# turn off last plot\n",
    "ax[-1, -1].axis('off')\n",
    "\n",
    "# change size xticks\n",
    "plt.xticks(size=20)\n",
    "\n",
    "# add legend\n",
    "ax[3][0].legend(loc=(1,0));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6e7e1c",
   "metadata": {},
   "source": [
    "<a name=\"combo_wordvec_adv_fea\"></a>\n",
    "## Combination of Wordvectors and Additional Features\n",
    "\n",
    "In this section both, the features gained from CountVectorization and the additional features from above (word embeddings, lenght of line, part of speech tagging) are used as predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9bd03f",
   "metadata": {},
   "source": [
    "<a name=\"combo_kvp\"></a>\n",
    "#### Kirk vs Picard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a6ddec",
   "metadata": {},
   "source": [
    "Creating the combined dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23f76b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining embedding features with pos-tagging and \n",
    "df_combo_kp = pd.concat([df_lines_kirk_picard_pos, pd.DataFrame(df_em_kp, index=df_lines_kirk_picard_pos.index)],\n",
    "                        axis=1)\n",
    "\n",
    "df_combo_kp.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6601d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the target\n",
    "target_kp = df_combo_kp.pop(\"character\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b74be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the train test split\n",
    "ttl_kp_combo = creating_tts_adv_fea(df_combo_kp, target_kp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0dda57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttl_kp_combo[0].shape, ttl_kp_combo[1].shape, ttl_kp_combo[2].shape, ttl_kp_combo[3].shape, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54539b13",
   "metadata": {},
   "source": [
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89122bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the \"line\" column to create word count features after train-test-split\n",
    "cvec_combo = CountVectorizer(stop_words = \"english\",  \n",
    "                             token_pattern=\"\\s(\\w{2,})\\s\",\n",
    "                             ngram_range =(1,1))\n",
    "\n",
    "\n",
    "lines_sparse_matrix_train = cvec_combo.fit_transform(ttl_kp_combo[0].line)\n",
    "lines_sparse_matrix_test = cvec_combo.transform(ttl_kp_combo[2].line)\n",
    "\n",
    "df_lines_kp_train = pd.DataFrame(lines_sparse_matrix_train.toarray(), columns=cvec_combo.get_feature_names(),\n",
    "                                 index= ttl_kp_combo[0].index)\n",
    "df_lines_kp_test = pd.DataFrame(lines_sparse_matrix_test.toarray(), columns=cvec_combo.get_feature_names(), \n",
    "                                index= ttl_kp_combo[2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93717aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine word counts with the other features, removing the line\n",
    "df_combo_kp_train = pd.concat([df_lines_kp_train, pd.DataFrame(ttl_kp_combo[0].loc[:,\"num_words\":])], axis=1)\n",
    "df_combo_kp_test = pd.concat([df_lines_kp_test, pd.DataFrame(ttl_kp_combo[2].loc[:,\"num_words\":])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700590dc",
   "metadata": {},
   "source": [
    "Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98814800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "scaler_combo_kp = StandardScaler()\n",
    "\n",
    "X_train_scaled_kp_combo = pd.DataFrame(scaler_combo_kp.fit_transform(df_combo_kp_train), \n",
    "                                 columns=df_combo_kp_train.columns)\n",
    "X_test_scaled_kp_combo = pd.DataFrame(scaler_combo_kp.transform(df_combo_kp_test), \n",
    "                                columns=df_combo_kp_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe12adae",
   "metadata": {},
   "source": [
    "Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefeaa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting a logistic regression grid search\n",
    "fit_pipeline(gs_logreg_em, X_train_scaled_kp_combo, ttl_kp_combo[1])\n",
    "logreg_combo_kp = gs_logreg_em.best_estimator_\n",
    "logreg_combo_kp_scores = get_scores(logreg_combo_kp, X_train_scaled_kp_combo, \n",
    "                                    ttl_kp_combo[1], X_test_scaled_kp_combo, ttl_kp_combo[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81300ea7",
   "metadata": {},
   "source": [
    "<a name=\"combo_allc\"></a>\n",
    "#### All captains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266457df",
   "metadata": {},
   "source": [
    "Creating the combined dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c32a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining features\n",
    "df_combo_allc = pd.concat([df_lines_all_captains_pos, \n",
    "                           pd.DataFrame(df_em_allc, index=df_lines_all_captains_pos.index)], axis=1)\n",
    "\n",
    "# fill missing values with 0\n",
    "df_combo_allc.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f4ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target\n",
    "target_allc = df_combo_allc.pop(\"character\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd2a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train-test split\n",
    "ttl_allc_combo = creating_tts_adv_fea(df_combo_allc, target_allc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e7247e",
   "metadata": {},
   "source": [
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54594e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word-count features\n",
    "cvec_combo = CountVectorizer(stop_words = \"english\",  \n",
    "                             token_pattern=\"\\s(\\w{2,})\\s\",\n",
    "                             ngram_range =(1,1))\n",
    "\n",
    "\n",
    "lines_sparse_matrix_train = cvec_combo.fit_transform(ttl_allc_combo[0].line)\n",
    "lines_sparse_matrix_test = cvec_combo.transform(ttl_allc_combo[2].line)\n",
    "\n",
    "df_lines_allc_train = pd.DataFrame(lines_sparse_matrix_train.toarray(), columns=cvec_combo.get_feature_names(),\n",
    "                                 index= ttl_allc_combo[0].index)\n",
    "df_lines_allc_test = pd.DataFrame(lines_sparse_matrix_test.toarray(), columns=cvec_combo.get_feature_names(), \n",
    "                                index= ttl_allc_combo[2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa079cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining features\n",
    "df_combo_allc_train = pd.concat([df_lines_allc_train, \n",
    "                                 pd.DataFrame(ttl_allc_combo[0].loc[:,\"num_words\":])], axis=1)\n",
    "df_combo_allc_test = pd.concat([df_lines_allc_test, \n",
    "                                pd.DataFrame(ttl_allc_combo[2].loc[:,\"num_words\":])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6416792",
   "metadata": {},
   "source": [
    "Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the data\n",
    "scaler_combo_allc = StandardScaler()\n",
    "\n",
    "X_train_scaled_allc_combo = pd.DataFrame(scaler_combo_allc.fit_transform(df_combo_allc_train), \n",
    "                                 columns=df_combo_allc_train.columns)\n",
    "X_test_scaled_allc_combo = pd.DataFrame(scaler_combo_allc.transform(df_combo_allc_test), \n",
    "                                columns=df_combo_allc_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ebd4fd",
   "metadata": {},
   "source": [
    "Creating a PCA version (1000 components) for faster model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04616bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset with PCA components for faster model testing\n",
    "pca = PCA(n_components=1000)\n",
    "\n",
    "X_train_scaled_allc_combo_pca = pca.fit_transform(X_train_scaled_allc_combo)\n",
    "X_test_scaled_allc_combo_pca = pca.transform(X_test_scaled_allc_combo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f7c809",
   "metadata": {},
   "source": [
    "Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5755bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pipeline(gs_logreg_em_fast, X_train_scaled_allc_combo_pca, ttl_allc_combo[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c682e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_combo_allc = gs_logreg_em_fast.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f1586",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_combo_allc_scores = get_scores(logreg_combo_allc, X_train_scaled_allc_combo_pca,ttl_allc_combo[1], \n",
    "           X_test_scaled_allc_combo_pca, ttl_allc_combo[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f195d22",
   "metadata": {},
   "source": [
    "<a name=\"xgb_main\"></a>\n",
    "## XGBoosted Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ded7584",
   "metadata": {},
   "source": [
    "#### Singular Tree for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9841d788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline to fit a decision tree\n",
    "pipe_dectree = Pipeline([\n",
    "    ('DecTree', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "param_grid_dectree = {\n",
    "              \"DecTree__max_depth\" : np.linspace(2,20,4, dtype=int),\n",
    "              \"DecTree__min_samples_split\": np.linspace(2, 10, 2, dtype=int),\n",
    "              \"DecTree__min_samples_leaf\": np.linspace(2, 10, 2, dtype=int)}\n",
    "\n",
    "gs_dectree_fast = GridSearchCV(pipe_dectree, param_grid_dectree, n_jobs=-2, verbose=3,cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd1075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit decision tree\n",
    "fit_pipeline(gs_dectree_fast, X_train_scaled_allc_combo_pca, ttl_allc_combo[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde62bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get decision tree parameters\n",
    "dectree_combo_allc = gs_dectree_fast.best_estimator_\n",
    "gs_dectree_fast.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78cebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out scores simple decision tree\n",
    "dectree_combo_allc_scores = get_scores(dectree_combo_allc, X_train_scaled_allc_combo_pca, ttl_allc_combo[1], \n",
    "           X_test_scaled_allc_combo_pca, ttl_allc_combo[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eb4957",
   "metadata": {},
   "source": [
    "### Data preparation for XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6123f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting target to floats for XGB algorithm:\n",
    "train_Y = [0 if t==\"archer\" else 1 if t==\"janeway\" \n",
    "           else 2 if t==\"kirk\" else 3 if t==\"picard\" \n",
    "           else 4 for t in ttl_allc_combo[1]]\n",
    "\n",
    "test_Y = [0 if t==\"archer\" else 1 if t==\"janeway\" \n",
    "           else 2 if t==\"kirk\" else 3 if t==\"picard\" \n",
    "           else 4 for t in ttl_allc_combo[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e9831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating smaller subset of the targets for testing algorithms\n",
    "train_Y_subset = train_Y[:2000]\n",
    "test_Y_subset = test_Y[:2000]\n",
    "\n",
    "# creating subset of the pca data (1000 features)\n",
    "train_X_pca_subset = X_train_scaled_allc_combo_pca[:2000]\n",
    "test_X_pca_subset = X_test_scaled_allc_combo_pca[:2000]\n",
    "\n",
    "# create subset of the full data (ca. 9000 features)\n",
    "train_X_subset = X_train_scaled_allc_combo[:2000]\n",
    "test_X_subset = X_test_scaled_allc_combo[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21fd4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column 133 (and 12, 20) because it creates a problem with the XGB algorithm because the \n",
    "# embedding feature 133 and the column of the string 133 are read as identical\n",
    "train_X_subset.drop(columns=[\"133\", \"12\", \"20\"], inplace=True)\n",
    "test_X_subset.drop(columns=[\"133\", \"12\", \"20\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccf9462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop relevant columns from the full dataframes\n",
    "X_train_scaled_allc_combo.drop(columns=[\"133\", \"12\", \"20\"], inplace=True)\n",
    "X_test_scaled_allc_combo.drop(columns=[\"133\", \"12\", \"20\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcf2ff7",
   "metadata": {},
   "source": [
    "### XGB Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54be9ce",
   "metadata": {},
   "source": [
    "#### XGB Model Nr 1 - Forest of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12770548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the number of rounds\n",
    "num_round = 200\n",
    "\n",
    "# create first XGBoost model \n",
    "param_xgboost = {\"max_depth\": 10, \"eta\":0.01, \n",
    "                 \"objective\":\"multi:softmax\", \n",
    "                 \"verbosity\":2, \"num_class\":5, \n",
    "                 \"num_parallel_tree\":3,\n",
    "                 \"nthread\":-2}\n",
    "\n",
    "# create train and test matrix from a subset of the data (2000 observations)\n",
    "xg_train = xgb.DMatrix(train_X_subset, label=train_Y_subset)\n",
    "xg_test = xgb.DMatrix(test_X_subset, label=test_Y_subset)\n",
    "\n",
    "# define watchlist\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f846de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train first XGB model\n",
    "bst = xgb.train(param_xgboost, xg_train, num_round, watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eeafba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print testscore first XGB Model\n",
    "pred = bst.predict(xg_test)\n",
    "\n",
    "# calculate accuracy\n",
    "sum(pred == test_Y_subset) / 2000    #division by 2000 because the model was run on a subset of 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6734c679",
   "metadata": {},
   "source": [
    "#### XGB Model Nr 2 - added Learning Rate Scheduler, Forest of 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deaa196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define the base learning rate and the round number\n",
    "eta_base = 0.1\n",
    "num_round = 100\n",
    "\n",
    "# define the decay of the learning rate\n",
    "eta_decay = np.linspace(eta_base, 0.01, num_round).tolist()\n",
    "\n",
    "# create a dictionary to collect logloss over epochs\n",
    "results_bb_1 = {} \n",
    "\n",
    "\n",
    "\n",
    "param_xgboost = {\"max_depth\": 3, \"eta\":eta_base, \n",
    "                 \"objective\":\"multi:softmax\", \n",
    "                 \"verbosity\":1, \"num_class\":5, \n",
    "                 \"num_parallel_tree\":20,\n",
    "                 \"nthread\":-2}\n",
    "\n",
    "# define train and test matrix (subset of 2000)\n",
    "xg_train = xgb.DMatrix(train_X_subset, label=train_Y_subset)\n",
    "xg_test = xgb.DMatrix(test_X_subset, label=test_Y_subset)\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "\n",
    "\n",
    "\n",
    "# train the model\n",
    "bst2 = xgb.train(param_xgboost, xg_train, num_round, \n",
    "                             watchlist, callbacks=[xgb.callback.LearningRateScheduler(eta_decay)],\n",
    "                             evals_result=results_bb_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eae68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = bst2.predict(xg_test)\n",
    "\n",
    "# calculate accuracy\n",
    "sum(pred2 == test_Y_subset) / 2000   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa897ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning over epochs\n",
    "plt.plot(results_bb_1[\"test\"][\"mlogloss\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a90cb3f",
   "metadata": {},
   "source": [
    "#### XGB Model Nr 3 - no Forest, more rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab16696b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define the base learning rate and the round number\n",
    "eta_base = 0.1\n",
    "num_round = 400\n",
    "\n",
    "# define the decay of the learning rate\n",
    "eta_decay = np.linspace(eta_base, 0.01,num_round).tolist()\n",
    "\n",
    "# create a dictionary to collect logloss over epochs\n",
    "results_bb_1 = {} \n",
    "\n",
    "\n",
    "\n",
    "param_xgboost = {\"max_depth\": 3, \"eta\":eta_base, \n",
    "                 \"objective\":\"multi:softmax\", \n",
    "                 \"verbosity\":1, \"num_class\":5, \n",
    "                 \"num_parallel_tree\":1,\n",
    "                 \"nthread\":-2}\n",
    "\n",
    "# this time define train and test matrix with all the data (not a subset)\n",
    "xg_train = xgb.DMatrix(X_train_scaled_allc_combo, label=train_Y)\n",
    "xg_test = xgb.DMatrix(X_test_scaled_allc_combo, label=test_Y)\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "\n",
    "\n",
    "                 \n",
    "\n",
    "# train the model\n",
    "bst3 = xgb.train(param_xgboost, xg_train, num_round, \n",
    "                             watchlist, callbacks=[xgb.callback.LearningRateScheduler(eta_decay)],\n",
    "                            evals_result=results_bb_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7988035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3 = bst3.predict(xg_test)\n",
    "\n",
    "# calculate accuracy\n",
    "sum(pred3 == test_Y) / 7111     # divide by 7111, the size of the full test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2638719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model learning\n",
    "plt.plot(results_bb_1[\"test\"][\"mlogloss\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f9e385",
   "metadata": {},
   "source": [
    "#### XGB Model Nr 4 - Forest of 7, max depth of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f888da26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# defining base learning rate and number of rounds\n",
    "eta_base = 0.2\n",
    "num_round = 500\n",
    "\n",
    "# define the decay of the learning rate over time\n",
    "eta_decay = np.linspace(eta_base, 0.02, num_round).tolist()\n",
    "\n",
    "# catch the mlogloss over rounds\n",
    "results_bb_2 = {} \n",
    "\n",
    "param_xgboost = {\"max_depth\": 3, \"eta\":eta_base, \n",
    "                 \"objective\":\"multi:softmax\", \n",
    "                 \"verbosity\":1, \"num_class\":5, \n",
    "                 \"num_parallel_tree\":7,\n",
    "                 \"nthread\":-2}\n",
    "\n",
    "xg_train = xgb.DMatrix(X_train_scaled_allc_combo, label=train_Y)\n",
    "xg_test = xgb.DMatrix(X_test_scaled_allc_combo, label=test_Y)\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "\n",
    "\n",
    "                           \n",
    "# train the model                         \n",
    "bst4 = xgb.train(param_xgboost, xg_train, num_round, \n",
    "                             watchlist, callbacks=[xgb.callback.LearningRateScheduler(eta_decay)],\n",
    "                            evals_result=results_bb_2, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9601c480",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4 = bst4.predict(xg_test)\n",
    "\n",
    "# calculate accuracy\n",
    "sum(pred4 == test_Y) /7111   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0a2abc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot learning rates\n",
    "plt.plot(results_bb_2[\"train\"][\"mlogloss\"], label=\"train\")\n",
    "plt.plot(results_bb_2[\"test\"][\"mlogloss\"], label=\"test\")\n",
    "\n",
    "plt.legend(loc=[1,0], title=\"mlogloss\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcb933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_for_xgb(y_test, y_predicted):\n",
    "    \"\"\"A function to plot a confusion matrix for an XGBoosted model.\n",
    "    Arguments:\n",
    "        y_test: list of correct answers\n",
    "        y_predicted: list of answers predictred by the model\"\"\"\n",
    "    \n",
    "    # create confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_predicted)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.clf()\n",
    "    \n",
    "    # show the plot to the computer\n",
    "    plt.imshow(cm, interpolation='nearest', \n",
    "               cmap=ListedColormap([\"#C6F6FA\", \"#7CEAF4\", \"#2FDEEE\", \"#0FAEBD\", \"#0B7A84\"]))\n",
    "               class_names = ['Archer','Janeway', 'Kirk', 'Picard', 'Sisko']\n",
    "    \n",
    "    # title, y and x label\n",
    "    plt.title('Confusion Matrix', font=\"DIN Condensed\", size=30)\n",
    "    plt.ylabel('True label', font=\"DIN Condensed\", size=20)\n",
    "    plt.xlabel('Predicted label', font=\"DIN Condensed\", size=20)\n",
    "    \n",
    "    # get x-ticks index\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    \n",
    "    # rename xticks mit class names\n",
    "    plt.xticks(tick_marks, class_names, rotation=45,  font=\"DIN Condensed\", size=20)\n",
    "    plt.yticks(tick_marks, class_names, font=\"DIN Condensed\", size=20)\n",
    "  \n",
    "    \n",
    "    # turn of gray grid\n",
    "    plt.grid(False)\n",
    "  \n",
    "    # add numbers of counts into the grid\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            plt.text(j-0.1,i+0.05, str(cm[i][j]), font=\"DIN Condensed\", size=20)\n",
    "      \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d88443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "confusion_matrix_for_xgb(test_Y, pred4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67329679",
   "metadata": {},
   "source": [
    "<a name=\"interaction_networks\"></a>\n",
    "# Interaction Networks\n",
    "\n",
    "This section explores who talks after whom as a proxy for character interaction, since most of the time a character is proceeded by the person they are talking to. This information is used to plot interaction networks of the 15 characters per series with the most lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1e2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edges_one_series(df_series_raw):\n",
    "    \"\"\"Function to create a list of tuples of characters speaking after each other.\n",
    "    Arguments:\n",
    "        df_series_raw = dataframe of all scripts in a series.\"\"\"\n",
    "    edges_series = []\n",
    "    \n",
    "    # iterates through episodes\n",
    "    for episode in range(0,len(df_series_raw)):\n",
    "        if episode in df_series_raw.index:   #checks whether an episode of that index number exist for the series\n",
    "            for script in range(0,len(find_names_and_lines(df_series_raw.script[episode]))-1):\n",
    "                \n",
    "                # uses find_names_and_lines() to separate names and lines\n",
    "                names_and_lines = find_names_and_lines(df_series_raw.script[episode]) \n",
    "                character_1 = names_and_lines[script][0].replace(\"[OC]\",\"\").strip(\" \")\n",
    "                character_2 = names_and_lines[script+1][0].replace(\"[OC]\",\"\").strip(\" \")\n",
    "                \n",
    "                edges_series.append((character_1, character_2))\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return edges_series\n",
    "\n",
    "\n",
    "def create_weight_dictionary_one_series(edges_series):\n",
    "    \"\"\"Function to create a dictionary of edges and their frequency in a series.\n",
    "    Arguments:\n",
    "        edges_series = list of tuples of connections in a series.\"\"\"\n",
    "    weight_dict = {}\n",
    "    inverse_pairs = set()\n",
    "    for pair in edges_series:\n",
    "        inverse_pair = (pair[1], pair[0])\n",
    "        if pair not in inverse_pairs:\n",
    "            try:\n",
    "                weight_dict[pair] += 1\n",
    "            except:\n",
    "                weight_dict[pair] = 1\n",
    "            inverse_pairs.add(inverse_pair)\n",
    "        else:\n",
    "            weight_dict[inverse_pair] += 1  \n",
    "    return weight_dict\n",
    "\n",
    "\n",
    "def sort_dict(dictionary):\n",
    "    \"\"\"Takes in a dictionary and returns it sorted by value.\"\"\"\n",
    "    return {k:v for k,v in sorted(dictionary.items(), key= lambda x: -x[1]) if k[0] != k[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfecd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_count_lines_per_character(df_series_raw):\n",
    "    \"\"\"Counts how many lines each character says in a series , returns a dictionary of character : count.\n",
    "    Arguments:\n",
    "        df_series_raw = dataframe of all scripts in a series.\"\"\"\n",
    "    dict_appearances_char_series = {}\n",
    "    for episode in range(0,len(df_series_raw)):\n",
    "        if episode in df_series_raw.index:\n",
    "            for script in range(0,len(find_names_and_lines(df_series_raw.script[episode]))):\n",
    "                character = find_names_and_lines(df_series_raw.script[episode])[script][0].replace(\"[OC]\",\"\").strip(\" \")\n",
    "                try:\n",
    "                    dict_appearances_char_series[character] += 1\n",
    "                except:\n",
    "                    dict_appearances_char_series[character] = 1\n",
    "                \n",
    "    return sort_dict(dict_appearances_char_series)\n",
    "\n",
    "\n",
    "def filter_edge_dict_by_character_list(character_list, weighted_edge_dict):\n",
    "    new_edge_dict = {}\n",
    "    for entry, weight in weighted_edge_dict.items():\n",
    "        if ((entry[0] in character_list)&(entry[1] in character_list)):\n",
    "            new_edge_dict[entry] = weight\n",
    "    return new_edge_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f98826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the characters of each series sorted by number of lines said\n",
    "top_chars_TOS = get_sorted_count_lines_per_character(df_TOS_raw)\n",
    "top_chars_TNG = get_sorted_count_lines_per_character(df_TNG_raw)\n",
    "top_chars_DS9 = get_sorted_count_lines_per_character(df_DS9_raw)\n",
    "top_chars_VOY = get_sorted_count_lines_per_character(df_VOY_raw)\n",
    "top_chars_ENT = get_sorted_count_lines_per_character(df_ENT_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55bbc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 15 characters with most lines said per series\n",
    "top_15_chars_TOS = list(top_chars_TOS)[:15]\n",
    "top_15_chars_TNG = list(top_chars_TNG)[:15]\n",
    "top_15_chars_DS9 = list(top_chars_DS9)[:15]\n",
    "top_15_chars_VOY = list(top_chars_VOY)[:15]\n",
    "top_15_chars_ENT = list(top_chars_ENT)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23e374",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get edges of all contacts per series defined as contacts between characters\n",
    "edges_TOS = edges_one_series(df_TOS_raw)\n",
    "edges_TNG = edges_one_series(df_TNG_raw)\n",
    "edges_DS9 = edges_one_series(df_DS9_raw)\n",
    "edges_VOY = edges_one_series(df_VOY_raw)\n",
    "edges_ENT = edges_one_series(df_ENT_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8754bec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the weight of the edges defined as counts of character contacts\n",
    "weight_dict_edges_TOS = create_weight_dictionary_one_series(edges_TOS)\n",
    "weight_dict_edges_TNG = create_weight_dictionary_one_series(edges_TNG)\n",
    "weight_dict_edges_DS9 = create_weight_dictionary_one_series(edges_DS9)\n",
    "weight_dict_edges_VOY = create_weight_dictionary_one_series(edges_VOY)\n",
    "weight_dict_edges_ENT = create_weight_dictionary_one_series(edges_ENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d13709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the dictionaries by weight\n",
    "weight_dict_edges_TOS_sort = sort_dict(weight_dict_edges_TOS)\n",
    "weight_dict_edges_TNG_sort = sort_dict(weight_dict_edges_TNG)\n",
    "weight_dict_edges_DS9_sort = sort_dict(weight_dict_edges_DS9)\n",
    "weight_dict_edges_VOY_sort = sort_dict(weight_dict_edges_VOY)\n",
    "weight_dict_edges_ENT_sort = sort_dict(weight_dict_edges_ENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060b25ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 15 characters with most lines with their respective weights and edges\n",
    "top_15_weight_dict_TOS = filter_edge_dict_by_character_list(top_15_chars_TOS, weight_dict_edges_TOS_sort)\n",
    "top_15_weight_dict_TNG = filter_edge_dict_by_character_list(top_15_chars_TNG, weight_dict_edges_TNG_sort)\n",
    "top_15_weight_dict_DS9 = filter_edge_dict_by_character_list(top_15_chars_DS9, weight_dict_edges_DS9_sort)\n",
    "top_15_weight_dict_VOY = filter_edge_dict_by_character_list(top_15_chars_VOY, weight_dict_edges_VOY_sort)\n",
    "top_15_weight_dict_ENT = filter_edge_dict_by_character_list(top_15_chars_ENT, weight_dict_edges_ENT_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9df6fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create name mappings with the first letter capitalized, the other letters lowercase\n",
    "names_mapping_TOS = {name: name[0] + name[1:].lower() for name in top_15_chars_TOS}\n",
    "names_mapping_TNG = {name: name[0] + name[1:].lower() for name in top_15_chars_TNG}\n",
    "names_mapping_DS9 = {name: name[0] + name[1:].lower() for name in top_15_chars_DS9}\n",
    "names_mapping_VOY = {name: name[0] + name[1:].lower() for name in top_15_chars_VOY}\n",
    "names_mapping_ENT = {name: name[0] + name[1:].lower() for name in top_15_chars_ENT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79972db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network plotting function\n",
    "def plot_spiral_network(top_chars_list, dict_with_weights):\n",
    "    \"\"\"This function plots a spiral network graph from the top 15 characters in a list and the\n",
    "    number of their interactions with each other.\n",
    "    Arguments:\n",
    "        top_chars_list: a list of the characters of interest\n",
    "        dict_with_weights: a dictionary containing the weights of the edges between the top 15 characters\"\"\"\n",
    "    \n",
    "    # create graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # add nodes (characters) and edges (their interactions)\n",
    "    G.add_nodes_from(top_chars_list)\n",
    "    G.add_edges_from(dict_with_weights.keys())\n",
    "\n",
    "    # create lists of edges with different weights\n",
    "    over_3000 = [k for k,v in dict_with_weights.items() if v >= 2000]\n",
    "    over_1000 = [k for k,v in dict_with_weights.items() if 3000 > v >= 1000]\n",
    "    over_500 = [k for k,v in dict_with_weights.items() if 1000 > v >= 500]\n",
    "    over_100 = [k for k,v in dict_with_weights.items() if 500 > v >= 100]\n",
    "    over_50 = [k for k,v in dict_with_weights.items() if 100 > v >= 50]\n",
    "    over_10 = [k for k,v in dict_with_weights.items() if 50 > v >= 10]\n",
    "    under_10 = [k for k,v in dict_with_weights.items() if v < 10]\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "\n",
    "    pos = nx.drawing.spiral_layout(G)\n",
    "    \n",
    "    # plot nodes and labels\n",
    "    nx.draw_networkx_nodes(G, pos=pos, node_color=\"lightgrey\", node_size=10, label=50)\n",
    "    nx.draw_networkx_labels(G, pos=pos, labels=top_chars_list)\n",
    "\n",
    "    # add edges formated conditionally on weights\n",
    "    nx.draw_networkx_edges(G, pos=pos, edge_color='grey', edgelist=under_10, width=0.2)\n",
    "    nx.draw_networkx_edges(G, pos=pos, edge_color='grey', edgelist=over_10, width=1, style=\"dashed\")\n",
    "    nx.draw_networkx_edges(G, pos=pos, edge_color='grey', edgelist=over_50, width=3, style=\"dashed\")\n",
    "    nx.draw_networkx_edges(G, pos=pos, edge_color='#44DEC0', edgelist=over_100, width=3)\n",
    "    nx.draw_networkx_edges(G, pos=pos, edge_color='#BADE44', edgelist=over_500, width=6)\n",
    "    nx.draw_networkx_edges(G, pos=pos, edge_color='#DEBE44', edgelist=over_1000, width=9)\n",
    "    nx.draw_networkx_edges(G, pos=pos, edge_color='#E69119', edgelist=over_3000, width=12)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4595b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spiral_network(names_mapping_TOS, top_15_weight_dict_TOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b62ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spiral_network(names_mapping_TNG, top_15_weight_dict_TNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cca6ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spiral_network(names_mapping_DS9, top_15_weight_dict_DS9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e96c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spiral_network(names_mapping_VOY, top_15_weight_dict_VOY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c01949",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spiral_network(names_mapping_ENT, top_15_weight_dict_ENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3655520",
   "metadata": {},
   "source": [
    "<a name=\"exp_data_game\"></a>\n",
    "## Export data for the browser game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fab71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class indices to class names\n",
    "predictions_boosted = [\"archer\" if t==0 else \"janeway\" if t==1\n",
    "           else \"kirk\" if t==2 else \"picard\" if t==3\n",
    "           else \"sisko \"for t in pred4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9148f9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### data for the game from the XGB model\n",
    "saving_destiny = \"/Users/tjanif/GA/GuessTheCaptain/content/\"\n",
    "\n",
    "ttl_allc_combo[2].to_csv(saving_destiny + \"_test_lines_all_captains.csv\")     # exports the testset of lines\n",
    "ttl_allc_combo[3].to_csv(saving_destiny + \"_test_answers_all_captains.csv\")   # exports the correct anwers\n",
    "pd.Series(predictions_boosted).to_csv(saving_destiny + \"_model_answers.csv\")  # exports the model's answers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
